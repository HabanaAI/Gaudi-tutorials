{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f61501b-41a9-41c4-aa91-bab3d88b1aa5",
   "metadata": {},
   "source": [
    "Copyright (c) 2023 Habana Labs, Ltd. an Intel Company.\n",
    "\n",
    "#### Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License. You may obtain a copy of the License at https://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b262c18-b8b9-4a33-ac24-13b310175991",
   "metadata": {},
   "source": [
    "# Running GPT model on DeepSpeed Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde6eb27-5fca-4e5d-abbe-faa5b41743d3",
   "metadata": {},
   "source": [
    "The objective is to take the original DeepSpeed example from [Lightning-GPT](https://github.com/Lightning-Universe/lightning-GPT) and show the same functionality on Gaudi2. This tutorial will show how to run the model and show the changes that were made to the original code to make the model run on the Gaudi2 HPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be275106-42d8-4718-a634-88ee94103874",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Please follow the instructions provided in the [Gaudi Installation Guide](https://docs.habana.ai/en/latest/Installation_Guide/GAUDI_Installation_Guide.html) to set up the environment including the `$PYTHON` environment variable. The guide will walk you through the process of setting up your system to run the model on Gaudi.   **You will need to run the latest Habana PyTorch Docker image, which includes the PyTorch Lightning Support for Gaudi**\n",
    "\n",
    "### Clone Habana Model-References\n",
    "\n",
    "In the docker container, clone the Gaudi-tutorials repository and switch to the branch that matches your SynapseAI version. You can run the [`hl-smi`](https://docs.habana.ai/en/latest/Management_and_Monitoring/System_Management_Tools_Guide/System_Management_Tools.html#hl-smi-utility-options) utility to determine the SynapseAI version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fd46b9b-0936-45b6-b353-8034d2dad11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/Gaudi-tutorials/Lightning/DeepSpeed_Lightning\n"
     ]
    }
   ],
   "source": [
    "%cd /root/Gaudi-tutorials/Lightning/DeepSpeed_Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8d4a74-d504-4d35-b688-ca2b92f15284",
   "metadata": {},
   "source": [
    "### Install Dependencies\n",
    "\n",
    "Please use the following commands to install dependent packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19065321-3728-42be-84cb-fdba5fe132fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b934be-f574-48e2-8e0f-6476706a0d9c",
   "metadata": {},
   "source": [
    "### Install Habana DeepSpeed\n",
    "\n",
    "Please follow the instructions provided in the [Gaudi DeepSpeed User Guide](https://docs.habana.ai/en/latest/PyTorch/DeepSpeed/DeepSpeed_User_Guide.html) to install the DeepSpeed on Gaudi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b48e41-680c-4d09-bc1c-e3371fd73da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/HabanaAI/DeepSpeed.git@1.21.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccd55c0-5ff6-4618-9ee7-3fd5ec5ffc27",
   "metadata": {},
   "source": [
    "## Run the model\n",
    "\n",
    "The command below will run the simple MinGPT DeepSpeed model on eight Gaudi2 Devices. By default, the model uses DeepSpeed ZeRO2. \n",
    "\n",
    "### Run command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e9b383-61e5-4ab3-adde-3f9ecc43f038",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /root/Gaudi-tutorials/Lightning/DeepSpeed_Lightning\n",
    "!python train.py --implementation mingpt --strategy deepspeed --model_type gpt2-xl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015c617a-d59b-4567-9970-71f2b8de2681",
   "metadata": {},
   "source": [
    "### Sample output\n",
    "```\n",
    "Training: 0it [00:00, ?it/s]\n",
    "Training:   0%|          | 0/70 [00:00<?, ?it/s]\n",
    "Epoch 0:   0%|          | 0/70 [00:00<?, ?it/s] \n",
    "Epoch 0:   1%|▏         | 1/70 [00:05<06:07,  5.32s/it]\n",
    "Epoch 0:   1%|▏         | 1/70 [00:05<06:07,  5.32s/it, v_num=0]\n",
    "Epoch 0:   3%|▎         | 2/70 [00:05<03:04,  2.71s/it, v_num=0]\n",
    "Epoch 0:   3%|▎         | 2/70 [00:05<03:04,  2.71s/it, v_num=0]\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0c5f44-448e-434e-bccf-6e19f90ad868",
   "metadata": {},
   "source": [
    "## Changes made to minGPT with Deepspeed on Gaudi2\n",
    "These five areas were changed to support DeepSpeed on Gaudi2in this PyTorch Lightning model, for more information, you can refer to the [Getting Started](https://lightning.ai/docs/pytorch/latest/integrations/hpu/basic.html#run-on-gaudi) section in the PyTorch Lightning documentation for basic model adoption.\n",
    "\n",
    "**1.** Change `lightning-GPT/train.py` as follows, adding Habana customized optimizer `DeepSpeedCPUAdam, FusedAdam` from `deepspeed.ops.adam`, scheduler `WarmupLR` from `deepspeed.runtime.lr_schedules`, and other necessary modules from either `lightning` or `pytorch_lightning`.\n",
    "\n",
    "Note that `lightning` has a higher priority than `pytorch_lightning`. We check whether `lightning` is available. If it is available, the code will import `lightning`; otherwise, it will import `pytorch_lightning`.\n",
    "\n",
    "```\n",
    "    --- a/train.py\n",
    "    +++ b/train.py\n",
    "    @@ -1,13 +1,75 @@\n",
    "    from argparse import ArgumentParser\n",
    "    from urllib.request import urlopen\n",
    "\n",
    "    -import lightning as L\n",
    "    +from deepspeed.ops.adam import DeepSpeedCPUAdam, FusedAdam\n",
    "    +from deepspeed.runtime.lr_schedules import WarmupLR\n",
    "    +\n",
    "    +from lightning_utilities import module_available\n",
    "    +if module_available(\"lightning\"):\n",
    "    +    import lightning.pytorch as L\n",
    "    +    from lightning.pytorch.callbacks import Callback, LearningRateMonitor, ModelCheckpoint\n",
    "    +    from lightning.pytorch.loggers import WandbLogger\n",
    "    +    from lightning.pytorch.plugins import DeepSpeedPrecisionPlugin\n",
    "    +    from lightning.pytorch.profilers.pytorch import PyTorchProfiler\n",
    "    +    from lightning.pytorch.strategies import StrategyRegistry\n",
    "    +    from lightning.pytorch.utilities.types import STEP_OUTPUT\n",
    "    +elif module_available(\"pytorch_lightning\"):\n",
    "    +    import pytorch_lightning as L\n",
    "    +    from pytorch_lightning.callbacks import Callback, LearningRateMonitor, ModelCheckpoint\n",
    "    +    from pytorch_lightning.loggers import WandbLogger\n",
    "    +    from pytorch_lightning.plugins import DeepSpeedPrecisionPlugin\n",
    "    +    from pytorch_lightning.profilers.pytorch import PyTorchProfiler\n",
    "    +    from pytorch_lightning.strategies import StrategyRegistry\n",
    "    +    from pytorch_lightning.utilities.types import STEP_OUTPUT\n",
    "```\n",
    "\n",
    "**2.** Similarly, change other files, such as `lightning_gpt/bench.py`, `lightning_gpt/callbacks.py`, `lightning_gpt/models.py`, to import necessary modules from either `lightning` or `pytorch_lightning`.\n",
    "    \n",
    "This is an example showing how to change `lightning_gpt/bench.py`.\n",
    "\n",
    "```\n",
    "    --- a/lightning_gpt/bench.py\n",
    "    +++ b/lightning_gpt/bench.py\n",
    "    @@ -3,7 +3,12 @@ import time\n",
    "    from typing import Any, Callable, Dict, Iterable, List, Optional, Type, Union\n",
    "    \n",
    "    import torch\n",
    "    -from lightning import CloudCompute, LightningFlow, LightningWork\n",
    "    +from lightning_utilities import module_available\n",
    "    +if module_available(\"lightning\"):\n",
    "    +    import lightning.pytorch as L\n",
    "    +elif module_available(\"pytorch_lightning\"):\n",
    "    +    import pytorch_lightning as L\n",
    "    +from lightning.app import CloudCompute, LightningFlow, LightningWork\n",
    "    from lightning.app.components import LightningTrainerMultiNode\n",
    "```\n",
    "\n",
    "**3.** Also, we need to import `habana_frameworks.torch.core` and `import habana_frameworks.torch.hpu` to load necessary Habana libraries. In `lightning-GPT/train.py`, add the following:\n",
    " \n",
    "```\n",
    "    --- a/train.py\n",
    "    +++ b/train.py\n",
    "    @@ -1,13 +1,75 @@\n",
    "\n",
    "    +try:\n",
    "    +    import habana_frameworks.torch.core as htcore\n",
    "    +    import habana_frameworks.torch.hpu as hthpu\n",
    "    +except:\n",
    "    +    print('INFO: no habana framework package installed')\n",
    "```\n",
    "\n",
    "**4.** In order to run the model on HPU, we need to use Habana customized class `HPUAccelerator`, `HPUDeepSpeedStrategy`, `HPUParallelStrategy`, and `DeepSpeedPrecisionPlugin`. \n",
    "\n",
    "4.1. Note that we have already imported `DeepSpeedPrecisionPlugin` in `lightning-GPT/train.py` in Step 1. We just need to import `HPUAccelerator`, `HPUDeepSpeedStrategy`, and `HPUParallelStrategy` as follows in `lightning-GPT/train.py`:\n",
    "\n",
    "```\n",
    "    --- a/train.py\n",
    "    +++ b/train.py\n",
    "    @@ -1,13 +1,75 @@\n",
    "\n",
    "    +from lightning_habana.pytorch.accelerator import HPUAccelerator\n",
    "    +from lightning_habana.pytorch.strategies import HPUDeepSpeedStrategy, HPUParallelStrategy\n",
    "```\n",
    "\n",
    "4.2. Change `lightning.Trainer` in `lightning-GPT/train.py` as follows:\n",
    "\n",
    "```\n",
    "    --- a/train.py\n",
    "    +++ b/train.py\n",
    "\n",
    "    @@ -80,21 +142,61 @@ def main(args):\n",
    "            torch.set_float32_matmul_precision(\"high\")\n",
    "            callback_list.append(callbacks.CUDAMetricsCallback())\n",
    "    \n",
    "    -    trainer = L.Trainer.from_argparse_args(\n",
    "    -        args,\n",
    "    -        max_epochs=10,\n",
    "    -        gradient_clip_val=1.0,\n",
    "    -        callbacks=callback_list,\n",
    "    -        accelerator=\"auto\",\n",
    "    +    trainer = L.Trainer(#.from_argparse_args(\n",
    "    +        accelerator=HPUAccelerator(),#\"auto\",\n",
    "            devices=\"auto\",\n",
    "    -        precision=16,\n",
    "    +        strategy = HPUDeepSpeedStrategy(\n",
    "    +            stage=2, #cfg.deepspeed_stage,\n",
    "    +            logging_batch_size_per_gpu=1, #cfg.batch_size,\n",
    "    +            cpu_checkpointing=True,\n",
    "    +            allgather_bucket_size=5e8,\n",
    "    +            reduce_bucket_size=5e8,\n",
    "    +            pin_memory=True,\n",
    "    +            contiguous_memory_optimization=False,\n",
    "    +            process_group_backend=\"hccl\"\n",
    "    +            # add the option to load a config from json file with more deepspeed options\n",
    "    +            # note that if supplied all defaults are ignored - model settings defaults this arg to None\n",
    "    +            # config=cfg.deepspeed_cfg_file\n",
    "    +        ) if args.strategy == \"deepspeed\" else  HPUParallelStrategy(\n",
    "    +            bucket_cap_mb=125,\n",
    "    +            gradient_as_bucket_view=True,\n",
    "    +            static_graph=True\n",
    "    +        ),\n",
    "    +        callbacks=callback_list,\n",
    "    +        accumulate_grad_batches=1,\n",
    "    +        precision=\"bf16-mixed\" if args.strategy == \"deepspeed\" else \"16-mixed\",#16,\n",
    "    +        max_epochs=100,\n",
    "    +        num_nodes=1,\n",
    "    +        check_val_every_n_epoch=5000,\n",
    "    +        val_check_interval=50,\n",
    "    +        log_every_n_steps=10,\n",
    "    +        limit_val_batches=10,\n",
    "    +        max_steps=100,\n",
    "    +        gradient_clip_val=1.0,\n",
    "    +        plugins=[DeepSpeedPrecisionPlugin(precision=\"bf16-mixed\")] if args.strategy == \"deepspeed\" else None,\n",
    "        )\n",
    "```\n",
    "\n",
    "**5.** Use Habana customize optimizer `FusedAdamW` in `lightning_gpt/models.py` as follows:\n",
    "\n",
    "```\n",
    "    --- a/lightning_gpt/models.py\n",
    "    +++ b/lightning_gpt/models.py\n",
    "    import mingpt.model\n",
    "    @@ -323,9 +329,12 @@ def _get_deepspeed_optimizer(\n",
    "            return DeepSpeedCPUAdam(optim_groups, lr=learning_rate, betas=betas)\n",
    "    \n",
    "        elif fused_adam and _DEEPSPEED_AVAILABLE:\n",
    "    -        from deepspeed.ops.adam import FusedAdam\n",
    "    -        return FusedAdam(optim_groups, lr=learning_rate, betas=betas)\n",
    "    +        from habana_frameworks.torch.hpex.optimizers import FusedAdamW\n",
    "    +        return FusedAdamW(optim_groups, lr=learning_rate)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80b13b-41c7-4baf-8b59-00f1ff88c890",
   "metadata": {},
   "source": [
    "## Changelog\n",
    "### 1.11.0\n",
    " - Import Lightning/Lightning-habana, Habana customized DeepSpeed and other necessary packages.\n",
    " - Add new arguments following DeepSpeed's requirements.\n",
    " - Import habana_frameworks.torch.core to load necessary Habana libraries.\n",
    " - Import Habana customized class ```HPUAccelerator```, ```HPUDeepSpeedStrategy```, ```HPUParallelStrategy``` and ```DeepSpeedPrecisionPlugin```, and add them to ```lightning.trainer```.\n",
    " - Add Habana customized optimizer ```FusedAdamW``` in ```lightning_gpt/models.py```.\n",
    " - Enable generation by changing functions ```from_tokens``` and ```to_tokens``` in ```lightning_gpt/data.py```."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
