{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed7c167e",
   "metadata": {},
   "source": [
    "Copyright (c) 2022 Habana Labs, Ltd. an Intel Company.\n",
    "All rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad15876",
   "metadata": {},
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the “License”);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa64f15",
   "metadata": {},
   "source": [
    "you may not use this file except in compliance with the License. You may obtain a copy of the License at https://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an “AS IS” BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3bf2f8",
   "metadata": {},
   "source": [
    "# Inference on Gaudi - Example1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da08d6a5",
   "metadata": {},
   "source": [
    "This notebook is used as an example to show inference on the Gaudi Accelerator. This is using a simple model with the MNIST dataset. \n",
    "\n",
    "This tutorial will show how to infer an MNIST model using native pytorch api."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30faf391",
   "metadata": {},
   "source": [
    "Download pretrained model checkpoints from vault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54fb526e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-16 22:16:40--  https://vault.habana.ai/artifactory/misc/inference/mnist/mnist-epoch_20.pth\n",
      "Resolving vault.habana.ai (vault.habana.ai)... 52.40.5.152, 35.161.38.78, 34.216.183.243, ...\n",
      "Connecting to vault.habana.ai (vault.habana.ai)|52.40.5.152|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 \n",
      "Resolving jfrog-prod-usw2-shared-oregon-main.s3.amazonaws.com (jfrog-prod-usw2-shared-oregon-main.s3.amazonaws.com)... 52.218.133.65, 52.218.221.219, 52.218.200.130, ...\n",
      "Connecting to jfrog-prod-usw2-shared-oregon-main.s3.amazonaws.com (jfrog-prod-usw2-shared-oregon-main.s3.amazonaws.com)|52.218.133.65|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 874335 (854K) [application/octet-stream]\n",
      "Saving to: ‘mnist-epoch_20.pth’\n",
      "\n",
      "mnist-epoch_20.pth  100%[===================>] 853.84K  2.20MB/s    in 0.4s    \n",
      "\n",
      "2023-03-16 22:16:42 (2.20 MB/s) - ‘mnist-epoch_20.pth’ saved [874335/874335]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://vault.habana.ai/artifactory/misc/inference/mnist/mnist-epoch_20.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862ddea3",
   "metadata": {},
   "source": [
    "Import all neccessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc33d654",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import time\n",
    "import habana_frameworks.torch as ht\n",
    "import habana_frameworks.torch.core as htcore\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c6b182",
   "metadata": {},
   "source": [
    "Define a simple Net model for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87308fa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1   = nn.Linear(784, 256)\n",
    "        self.fc2   = nn.Linear(256, 64)\n",
    "        self.fc3   = nn.Linear(64, 10)\n",
    "    def forward(self, x):\n",
    "        out = x.view(-1,28*28)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0001ad11",
   "metadata": {},
   "source": [
    "Create the model, and load the pre-trained checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dae33a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "checkpoint = torch.load('mnist-epoch_20.pth')\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9719268",
   "metadata": {},
   "source": [
    "Optimize the model for eval, and move the model to Gaudi(hpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a02a7150",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=============================HABANA PT BRIDGE CONFIGURATION =========================== \n",
      " PT_HPU_LAZY_MODE = 1\n",
      " PT_HPU_LAZY_EAGER_OPTIM_CACHE = 1\n",
      " PT_HPU_ENABLE_COMPILE_THREAD = 0\n",
      " PT_HPU_ENABLE_EXECUTION_THREAD = 1\n",
      " PT_HPU_ENABLE_LAZY_EAGER_EXECUTION_THREAD = 1\n",
      " PT_ENABLE_INTER_HOST_CACHING = 0\n",
      " PT_ENABLE_INFERENCE_MODE = 1\n",
      " PT_ENABLE_HABANA_CACHING = 1\n",
      " PT_HPU_MAX_RECIPE_SUBMISSION_LIMIT = 0\n",
      " PT_HPU_MAX_COMPOUND_OP_SIZE = 9223372036854775807\n",
      " PT_HPU_MAX_COMPOUND_OP_SIZE_SS = 10\n",
      " PT_HPU_ENABLE_STAGE_SUBMISSION = 1\n",
      " PT_HPU_STAGE_SUBMISSION_MODE = 2\n",
      " PT_HPU_PGM_ENABLE_CACHE = 1\n",
      " PT_HPU_ENABLE_LAZY_COLLECTIVES = 0\n",
      " PT_HCCL_SLICE_SIZE_MB = 16\n",
      " PT_HCCL_MEMORY_ALLOWANCE_MB = 0\n",
      " PT_HPU_INITIAL_WORKSPACE_SIZE = 0\n",
      " PT_HABANA_POOL_SIZE = 24\n",
      " PT_HPU_POOL_STRATEGY = 5\n",
      " PT_HPU_POOL_LOG_FRAGMENTATION_INFO = 0\n",
      " PT_ENABLE_MEMORY_DEFRAGMENTATION = 1\n",
      " PT_ENABLE_DEFRAGMENTATION_INFO = 0\n",
      " PT_HPU_ENABLE_SYNAPSE_LAYOUT_HANDLING = 1\n",
      " PT_HPU_ENABLE_SYNAPSE_OUTPUT_PERMUTE = 1\n",
      " PT_HPU_ENABLE_VALID_DATA_RANGE_CHECK = 1\n",
      " PT_HPU_FORCE_USE_DEFAULT_STREAM = 0\n",
      " PT_RECIPE_CACHE_PATH = \n",
      " PT_HPU_ENABLE_REFINE_DYNAMIC_SHAPES = 0\n",
      " PT_HPU_DYNAMIC_MIN_POLICY_ORDER = 4,5,3,1\n",
      " PT_HPU_DYNAMIC_MAX_POLICY_ORDER = 2,4,5,3,1\n",
      " PT_HPU_LAZY_ACC_PAR_MODE = 1\n",
      "=============================SYSTEM CONFIGURATION ========================================= \n",
      "Num CPU Cores = 96\n",
      "CPU RAM = 784300908 KB \n",
      "============================================================================================ \n"
     ]
    }
   ],
   "source": [
    "model = model.eval()\n",
    "model = model.to(\"hpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8850e356",
   "metadata": {},
   "source": [
    "Create a MNIST datasets for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd3ea695",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9912422/9912422 [00:00<00:00, 353255599.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28881/28881 [00:00<00:00, 86217575.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1648877/1648877 [00:00<00:00, 254644552.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00<00:00, 15000416.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "data_path = './data'\n",
    "test_kwargs = {'batch_size': 32}\n",
    "dataset1 = datasets.MNIST(data_path, train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(dataset1,**test_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc2aeb4",
   "metadata": {},
   "source": [
    "Run Inference.\n",
    "For lazy mode, we need to call mark_step() after each inference to enforce the execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "908a04ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.36%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for batch_idx, (data, label) in enumerate(test_loader):\n",
    "    data = data.to(\"hpu\")\n",
    "    output = model(data)\n",
    "    #In Lazy mode execution, mark_step() need to be added after inference\n",
    "    htcore.mark_step()\n",
    "    correct += output.max(1)[1].eq(label).sum()\n",
    "\n",
    "print('Accuracy: {:.2f}%'.format(100. * correct / (len(test_loader) * 32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f68750d3-7226-4892-a6f5-a4037ad07502",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828a576d-d42d-484a-82f4-2f91dd3ff7c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
