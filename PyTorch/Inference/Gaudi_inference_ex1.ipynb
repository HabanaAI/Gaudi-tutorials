{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed7c167e",
   "metadata": {},
   "source": [
    "Copyright (c) 2022 Habana Labs, Ltd. an Intel Company.\n",
    "SPDX-License-Identifier: Apache-2.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3bf2f8",
   "metadata": {},
   "source": [
    "# Inference on Gaudi - Example1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da08d6a5",
   "metadata": {},
   "source": [
    "This notebook is used as an example to show inference on the Gaudi Accelerator. This is using a simple model with the MNIST dataset. \n",
    "\n",
    "This tutorial will show how to infer an MNIST model using native pytorch api."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30faf391",
   "metadata": {},
   "source": [
    "Download pretrained model checkpoints from vault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fb526e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget https://vault.habana.ai/artifactory/misc/inference/mnist/mnist-epoch_20.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862ddea3",
   "metadata": {},
   "source": [
    "Import all neccessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc33d654",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#Enable PT_HPU_LAZY_MODE=1\n",
    "os.environ['PT_HPU_LAZY_MODE'] = '1'\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "import time\n",
    "import habana_frameworks.torch as ht\n",
    "import habana_frameworks.torch.core as htcore\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c6b182",
   "metadata": {},
   "source": [
    "Define a simple Net model for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87308fa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1   = nn.Linear(784, 256)\n",
    "        self.fc2   = nn.Linear(256, 64)\n",
    "        self.fc3   = nn.Linear(64, 10)\n",
    "    def forward(self, x):\n",
    "        out = x.view(-1,28*28)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0001ad11",
   "metadata": {},
   "source": [
    "Create the model, and load the pre-trained checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dae33a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Net()\n",
    "checkpoint = torch.load('mnist-epoch_20.pth')\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9719268",
   "metadata": {},
   "source": [
    "Optimize the model for eval, and move the model to Gaudi(hpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02a7150",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.eval()\n",
    "model = model.to(\"hpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8850e356",
   "metadata": {},
   "source": [
    "Create a MNIST datasets for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3ea695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "data_path = './data'\n",
    "test_kwargs = {'batch_size': 32}\n",
    "dataset1 = datasets.MNIST(data_path, train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(dataset1,**test_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc2aeb4",
   "metadata": {},
   "source": [
    "Run Inference.\n",
    "For lazy mode, we need to call mark_step() after each inference to enforce the execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908a04ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for batch_idx, (data, label) in enumerate(test_loader):\n",
    "    data = data.to(\"hpu\")\n",
    "    output = model(data)\n",
    "    #In Lazy mode execution, mark_step() need to be added after inference\n",
    "    htcore.mark_step()\n",
    "    correct += output.max(1)[1].eq(label).sum()\n",
    "\n",
    "print('Accuracy: {:.2f}%'.format(100. * correct / (len(test_loader) * 32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f68750d3-7226-4892-a6f5-a4037ad07502",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
