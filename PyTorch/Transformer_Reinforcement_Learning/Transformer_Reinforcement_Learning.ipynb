{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc00676b-8d19-4e0d-b61d-68ccc14c294d",
   "metadata": {},
   "source": [
    "Copyright (c) 2024 Habana Labs, Ltd. an Intel Company.\n",
    "\n",
    "##### Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License. You may obtain a copy of the License at https://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b714683-1b37-4048-bf91-2b5af1c18d40",
   "metadata": {},
   "source": [
    "## Intel® Gaudi® Accelerator Using Hugging Face Transformer Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6db2bc-12ef-47a0-83f8-cfba2a8af03c",
   "metadata": {},
   "source": [
    "\n",
    "This document provides instructions on setting up the Intel Gaudi 2 AI accelerator Instance on the Intel® Developer Cloud or any on-premise Intel Gaudi Node. You will be running models from the Intel Gaudi software Model References and the Hugging Face Optimum Habana library.\n",
    "\n",
    "This assumes that you have setup the latest Intel Gaudi PyTorch Docker image.\n",
    "\n",
    "The first step is to install the Optimum Habana repository from GitHub and run the demo of Transformer Reinforcement Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37216139-611e-4b07-a90f-cb351f18b185",
   "metadata": {},
   "source": [
    "### Fine-tuning with Hugging Face Optimum Habana Library\n",
    "The Optimum Habana library is the interface between the Hugging Face Transformers and Diffusers libraries and the Gaudi 2 card. It provides a set of tools enabling easy model loading, training and inference on single and multi-card settings for different downstream tasks. The following example use the DPO and PPO pipeline to fine-tune a Llama 2 7B model.  For more details, see the [TRL](https://github.com/huggingface/optimum-habana/tree/main/examples/trl) examples at the Optimum-Habana GitHub page. \n",
    "\n",
    "Follow the below steps to install the stable release from the Optimum Habana examples and library:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7420be01-fb88-466a-9fe7-87006340905f",
   "metadata": {},
   "source": [
    "1. Clone the Optimum-Habana project and check out the lastest stable release.  This repository gives access to the examples that are optimized for Intel Gaudi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07346c1a-1fea-4b62-8a79-760ca7a64073",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~\n",
    "!git clone https://github.com/huggingface/optimum-habana.git\n",
    "%cd optimum-habana\n",
    "!git checkout v1.13.2\n",
    "%cd ~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09ded02-2aa1-4725-b1fc-cf917e05d9aa",
   "metadata": {},
   "source": [
    "2. Install Optimum-Habana library. This will install the latest stable library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e35cc-0ea1-4205-ae70-323252169c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optimum-habana==1.13.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db627879-a273-4914-8efd-68c9a81ebbb9",
   "metadata": {},
   "source": [
    "3. In order to use the DeepSpeed library on Intel Gaudi 2, install the Intel Gaudi DeepSpeed fork:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59e99a7-4db0-4519-b406-ccedee40796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/HabanaAI/DeepSpeed.git@1.17.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25f0546-e74c-4363-b443-a0f59504d973",
   "metadata": {},
   "source": [
    "The following example is based on the Optimum-Habana TRL task example. Change to the trl directory and install the additional SW requirements for this specific example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24537f40-8daa-4ac9-ad19-bf1cfaaf29f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/optimum-habana/examples/trl/\n",
    "!pip install -U -r requirements.txt\n",
    "!pip install datasets==2.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af2bc05d-ae12-4e35-8e95-124b754d6d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token <your_token_here>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f04ce10",
   "metadata": {},
   "source": [
    "### DPO Pipeline\n",
    "\n",
    "#### Training\n",
    "\n",
    "The following example is for the creation of StackLlaMa 2: a Stack exchange llama-v2-7b model. There are two main steps to the DPO training process:\n",
    "\n",
    "1. Supervised fine-tuning of the base llama-v2-7b model to create llama-v2-7b-se:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01698aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:462: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:319: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.10/dist-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.10/dist-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.10/dist-packages/habana_frameworks/torch/hpu/__init__.py:158: UserWarning: torch.hpu.setDeterministic is deprecated and will be removed in next release. Please use torch.use_deterministic_algorithms instead.\n",
      "  warnings.warn(\n",
      "[2024-06-03 19:56:16,720] [INFO] [real_accelerator.py:178:get_accelerator] Setting ds_accelerator to hpu (auto detect)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:319: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:466: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "config.json: 100%|█████████████████████████████| 609/609 [00:00<00:00, 5.79MB/s]\n",
      "model.safetensors.index.json: 100%|████████| 26.8k/26.8k [00:00<00:00, 61.8MB/s]\n",
      "Downloading shards:   0%|                                 | 0/2 [00:00<?, ?it/s]\n",
      "model-00001-of-00002.safetensors:   0%|             | 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   0%|    | 10.5M/9.98G [00:00<05:59, 27.7MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  96%|███▊| 3.37G/3.50G [02:02<00:04, 27.6MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  96%|███▊| 3.38G/3.50G [02:03<00:04, 27.7MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors: 100%|███▉| 3.49G/3.50G [02:07<00:00, 27.4MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors: 100%|████| 3.50G/3.50G [02:07<00:00, 27.4MB/s]\u001b[A\n",
      "Downloading shards: 100%|████████████████████████| 2/2 [08:12<00:00, 246.45s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:01<00:00,  1.72it/s]\n",
      "generation_config.json: 100%|██████████████████| 188/188 [00:00<00:00, 3.31MB/s]\n",
      "tokenizer_config.json: 100%|███████████████████| 776/776 [00:00<00:00, 9.57MB/s]\n",
      "tokenizer.model: 100%|███████████████████████| 500k/500k [00:00<00:00, 31.6MB/s]\n",
      "tokenizer.json: 100%|██████████████████████| 1.84M/1.84M [00:00<00:00, 10.4MB/s]\n",
      "special_tokens_map.json: 100%|█████████████████| 414/414 [00:00<00:00, 2.13MB/s]\n",
      "/usr/local/lib/python3.10/dist-packages/datasets/load.py:2516: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n",
      "Downloading readme: 100%|██████████████████████| 737/737 [00:00<00:00, 3.55MB/s]\n",
      "Resolving data files: 100%|████████████████████| 20/20 [00:00<00:00, 111.20it/s]\n",
      "Loading the dataset in streaming mode\n",
      "100%|████████████████████████████████████████| 400/400 [00:03<00:00, 115.73it/s]\n",
      "The character to token ratio of the dataset is: 3.21\n",
      "/usr/local/lib/python3.10/dist-packages/optimum/habana/trl/trainer/sft_trainer.py:156: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "============================= HABANA PT BRIDGE CONFIGURATION =========================== \n",
      " PT_HPU_LAZY_MODE = 1\n",
      " PT_RECIPE_CACHE_PATH = \n",
      " PT_CACHE_FOLDER_DELETE = 0\n",
      " PT_HPU_RECIPE_CACHE_CONFIG = \n",
      " PT_HPU_MAX_COMPOUND_OP_SIZE = 9223372036854775807\n",
      " PT_HPU_LAZY_ACC_PAR_MODE = 1\n",
      " PT_HPU_ENABLE_REFINE_DYNAMIC_SHAPES = 0\n",
      "---------------------------: System Configuration :---------------------------\n",
      "Num CPU Cores : 160\n",
      "CPU RAM       : 1056433764 KB\n",
      "------------------------------------------------------------------------------\n",
      "/usr/local/lib/python3.10/dist-packages/optimum/habana/trl/trainer/sft_trainer.py:238: UserWarning: You passed `packing=True` to the SFTTrainer, and you are training your model with `max_steps` strategy. The dataset will be iterated until the `max_steps` are reached.\n",
      "  warnings.warn(\n",
      "{'loss': 1.5592, 'grad_norm': 0.06005859375, 'learning_rate': 1e-05, 'epoch': 0.02, 'memory_allocated (GB)': 48.85, 'max_memory_allocated (GB)': 94.0, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.5913, 'grad_norm': 0.05419921875, 'learning_rate': 2e-05, 'epoch': 0.04, 'memory_allocated (GB)': 48.85, 'max_memory_allocated (GB)': 94.02, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.5609, 'grad_norm': 0.06689453125, 'learning_rate': 3e-05, 'epoch': 0.06, 'memory_allocated (GB)': 48.85, 'max_memory_allocated (GB)': 94.03, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.417, 'grad_norm': 0.15625, 'learning_rate': 1.3815039801161721e-06, 'epoch': 0.94, 'memory_allocated (GB)': 48.85, 'max_memory_allocated (GB)': 94.09, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.4493, 'grad_norm': 0.15234375, 'learning_rate': 6.15582970243117e-07, 'epoch': 0.96, 'memory_allocated (GB)': 48.85, 'max_memory_allocated (GB)': 94.09, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.4409, 'grad_norm': 0.177734375, 'learning_rate': 1.5413331334360182e-07, 'epoch': 0.98, 'memory_allocated (GB)': 48.85, 'max_memory_allocated (GB)': 94.09, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.4848, 'grad_norm': 0.1806640625, 'learning_rate': 0.0, 'epoch': 1.0, 'memory_allocated (GB)': 48.85, 'max_memory_allocated (GB)': 94.09, 'total_memory_available (GB)': 94.62}\n",
      "{'train_runtime': 493.399, 'train_samples_per_second': 8.107, 'train_steps_per_second': 1.013, 'train_loss': 1.4994177131652833, 'epoch': 1.0, 'memory_allocated (GB)': 48.85, 'max_memory_allocated (GB)': 94.09, 'total_memory_available (GB)': 94.62}\n",
      "100%|█████████████████████████████████████████| 500/500 [08:13<00:00,  1.01it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:00<00:00,  2.39it/s]\n"
     ]
    }
   ],
   "source": [
    "!python sft.py \\\n",
    "    --model_name_or_path meta-llama/Llama-2-7b-hf \\\n",
    "    --output_dir=\"./sft\" \\\n",
    "    --max_steps=500 \\\n",
    "    --logging_steps=10 \\\n",
    "    --save_steps=100 \\\n",
    "    --per_device_train_batch_size=4 \\\n",
    "    --per_device_eval_batch_size=1 \\\n",
    "    --gradient_accumulation_steps=2 \\\n",
    "    --learning_rate=1e-4 \\\n",
    "    --lr_scheduler_type=\"cosine\" \\\n",
    "    --warmup_steps=100 \\\n",
    "    --weight_decay=0.05 \\\n",
    "    --optim=\"paged_adamw_32bit\" \\\n",
    "    --lora_target_modules \"q_proj\" \"v_proj\" \\\n",
    "    --bf16 \\\n",
    "    --remove_unused_columns=False \\\n",
    "    --run_name=\"sft_llama2\" \\\n",
    "    --report_to=none \\\n",
    "    --use_habana \\\n",
    "    --use_lazy_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d5158b",
   "metadata": {},
   "source": [
    "2. Run the DPO trainer using the model saved by the previous step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73ec49d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:462: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:319: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.10/dist-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:319: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.10/dist-packages/habana_frameworks/torch/hpu/__init__.py:158: UserWarning: torch.hpu.setDeterministic is deprecated and will be removed in next release. Please use torch.use_deterministic_algorithms instead.\n",
      "  warnings.warn(\n",
      "[2024-06-03 20:17:31,679] [INFO] [real_accelerator.py:178:get_accelerator] Setting ds_accelerator to hpu (auto detect)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:319: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:00<00:00, 11.02it/s]\n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:00<00:00, 10.41it/s]\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Resolving data files: 100%|████████████████████| 20/20 [00:00<00:00, 108.02it/s]\n",
      "Downloading data: 100%|██████████████████████| 315M/315M [00:12<00:00, 25.6MB/s]\n",
      "Downloading data: 100%|██████████████████████| 313M/313M [00:12<00:00, 25.7MB/s]\n",
      "Downloading data: 100%|██████████████████████| 314M/314M [00:12<00:00, 25.3MB/s]\n",
      "Downloading data: 100%|██████████████████████| 312M/312M [00:12<00:00, 25.5MB/s]\n",
      "Downloading data: 100%|██████████████████████| 313M/313M [00:12<00:00, 25.5MB/s]\n",
      "Generating train split: 7435908 examples [01:23, 89565.87 examples/s]\n",
      "Loading dataset shards: 100%|█████████████████| 42/42 [00:00<00:00, 1255.81it/s]\n",
      "Map (num_proc=24): 100%|████| 7435908/7435908 [02:02<00:00, 60604.61 examples/s]\n",
      "Filter: 100%|██████████████| 7435908/7435908 [00:32<00:00, 228972.89 examples/s]\n",
      "Downloading data: 100%|██████████████████████| 314M/314M [00:12<00:00, 25.3MB/s]\n",
      "Downloading data: 100%|██████████████████████| 315M/315M [00:12<00:00, 25.3MB/s]\n",
      "Downloading data: 100%|██████████████████████| 314M/314M [00:12<00:00, 25.1MB/s]\n",
      "Downloading data: 100%|██████████████████████| 314M/314M [00:15<00:00, 20.3MB/s]\n",
      "Generating train split: 4483004 examples [00:49, 89973.94 examples/s]\n",
      "Loading dataset shards: 100%|█████████████████| 26/26 [00:00<00:00, 1164.15it/s]\n",
      "Map (num_proc=24): 100%|███████████| 1000/1000 [00:00<00:00, 2957.00 examples/s]\n",
      "Filter: 100%|█████████████████████| 1000/1000 [00:00<00:00, 47038.75 examples/s]\n",
      "Parameter 'function'=<bound method DPOTrainer.tokenize_row of <optimum.habana.trl.trainer.dpo_trainer.GaudiDPOTrainer object at 0x75f790bf26b0>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Map: 100%|████████████████████| 1652614/1652614 [34:17<00:00, 803.24 examples/s]\n",
      "Map: 100%|████████████████████████████| 242/242 [00:00<00:00, 784.50 examples/s]\n",
      "============================= HABANA PT BRIDGE CONFIGURATION =========================== \n",
      " PT_HPU_LAZY_MODE = 1\n",
      " PT_RECIPE_CACHE_PATH = \n",
      " PT_CACHE_FOLDER_DELETE = 0\n",
      " PT_HPU_RECIPE_CACHE_CONFIG = \n",
      " PT_HPU_MAX_COMPOUND_OP_SIZE = 9223372036854775807\n",
      " PT_HPU_LAZY_ACC_PAR_MODE = 1\n",
      " PT_HPU_ENABLE_REFINE_DYNAMIC_SHAPES = 0\n",
      "---------------------------: System Configuration :---------------------------\n",
      "Num CPU Cores : 160\n",
      "CPU RAM       : 1056433764 KB\n",
      "------------------------------------------------------------------------------\n",
      "[WARNING] Variable keyword arguments will not be supported.\n",
      "  0%|                                                  | 0/1000 [00:00<?, ?it/s][WARNING] Variable keyword arguments will not be supported.\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n",
      "{'loss': 0.6981, 'grad_norm': 1.2265625, 'learning_rate': 5e-05, 'rewards/chosen': -0.01123046875, 'rewards/rejected': -0.006561279296875, 'rewards/accuracies': 0.30000001192092896, 'rewards/margins': -0.00469970703125, 'logps/rejected': -181.0, 'logps/chosen': -154.0, 'logits/rejected': 0.3116459846496582, 'logits/chosen': 0.3190951645374298, 'epoch': 0.0, 'memory_allocated (GB)': 57.96, 'max_memory_allocated (GB)': 83.99, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.6913, 'grad_norm': 2.09375, 'learning_rate': 0.0001, 'rewards/chosen': 0.001251220703125, 'rewards/rejected': -0.001251220703125, 'rewards/accuracies': 0.32499998807907104, 'rewards/margins': 0.00250244140625, 'logps/rejected': -158.0, 'logps/chosen': -158.0, 'logits/rejected': 0.3290488123893738, 'logits/chosen': 0.36778321862220764, 'epoch': 0.0, 'memory_allocated (GB)': 58.06, 'max_memory_allocated (GB)': 84.15, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.692, 'grad_norm': 2.6875, 'learning_rate': 0.00015, 'rewards/chosen': -0.014404296875, 'rewards/rejected': -0.018798828125, 'rewards/accuracies': 0.375, 'rewards/margins': 0.00439453125, 'logps/rejected': -140.0, 'logps/chosen': -147.0, 'logits/rejected': 0.34905093908309937, 'logits/chosen': 0.3333360254764557, 'epoch': 0.0, 'memory_allocated (GB)': 58.01, 'max_memory_allocated (GB)': 84.17, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.6925, 'grad_norm': 0.8203125, 'learning_rate': 0.0002, 'rewards/chosen': 0.0031280517578125, 'rewards/rejected': -0.00156402587890625, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 0.004669189453125, 'logps/rejected': -132.0, 'logps/chosen': -133.0, 'logits/rejected': 0.36356204748153687, 'logits/chosen': 0.37949246168136597, 'epoch': 0.0, 'memory_allocated (GB)': 58.02, 'max_memory_allocated (GB)': 84.25, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.684, 'grad_norm': 2.796875, 'learning_rate': 0.00025, 'rewards/chosen': -0.013427734375, 'rewards/rejected': -0.036376953125, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': 0.0228271484375, 'logps/rejected': -130.0, 'logps/chosen': -135.0, 'logits/rejected': 0.23999908566474915, 'logits/chosen': 0.25309091806411743, 'epoch': 0.0, 'memory_allocated (GB)': 58.03, 'max_memory_allocated (GB)': 84.25, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.6909, 'grad_norm': 2.140625, 'learning_rate': 0.0003, 'rewards/chosen': -0.09521484375, 'rewards/rejected': -0.11181640625, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 0.016845703125, 'logps/rejected': -161.0, 'logps/chosen': -164.0, 'logits/rejected': 0.005596156232059002, 'logits/chosen': 0.0138382064178586, 'epoch': 0.0, 'memory_allocated (GB)': 57.99, 'max_memory_allocated (GB)': 84.25, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.7059, 'grad_norm': 3.6875, 'learning_rate': 0.00035, 'rewards/chosen': -0.47265625, 'rewards/rejected': -0.4765625, 'rewards/accuracies': 0.5, 'rewards/margins': 0.0028076171875, 'logps/rejected': -160.0, 'logps/chosen': -148.0, 'logits/rejected': -0.3655722737312317, 'logits/chosen': -0.37922897934913635, 'epoch': 0.0, 'memory_allocated (GB)': 58.05, 'max_memory_allocated (GB)': 84.25, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.7877, 'grad_norm': 2.390625, 'learning_rate': 0.0004, 'rewards/chosen': -1.1328125, 'rewards/rejected': -1.03125, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -0.0966796875, 'logps/rejected': -173.0, 'logps/chosen': -168.0, 'logits/rejected': -0.44411468505859375, 'logits/chosen': -0.45304521918296814, 'epoch': 0.0, 'memory_allocated (GB)': 58.1, 'max_memory_allocated (GB)': 84.25, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.9602, 'grad_norm': 3.765625, 'learning_rate': 0.00045000000000000004, 'rewards/chosen': -1.7578125, 'rewards/rejected': -1.5, 'rewards/accuracies': 0.3499999940395355, 'rewards/margins': -0.259765625, 'logps/rejected': -161.0, 'logps/chosen': -176.0, 'logits/rejected': -0.5857728719711304, 'logits/chosen': -0.5913934111595154, 'epoch': 0.0, 'memory_allocated (GB)': 58.09, 'max_memory_allocated (GB)': 84.25, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.7345, 'grad_norm': 4.9375, 'learning_rate': 0.0005, 'rewards/chosen': -0.98046875, 'rewards/rejected': -0.96484375, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -0.0166015625, 'logps/rejected': -142.0, 'logps/chosen': -174.0, 'logits/rejected': 0.06756856292486191, 'logits/chosen': 0.06794492155313492, 'epoch': 0.0, 'memory_allocated (GB)': 58.0, 'max_memory_allocated (GB)': 84.25, 'total_memory_available (GB)': 94.62}\n",
      " 10%|████                                    | 100/1000 [03:25<27:12,  1.81s/it]\n",
      "  0%|                                                   | 0/242 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▎                                          | 2/242 [00:00<01:49,  2.18it/s]\u001b[A\n",
      "  1%|▌                                          | 3/242 [00:01<02:35,  1.54it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▍| 239/242 [03:41<00:02,  1.05it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▋| 240/242 [03:42<00:01,  1.08it/s]\u001b[A\n",
      "100%|████████████████████████████████████████▊| 241/242 [03:43<00:00,  1.11it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7843081951141357, 'eval_runtime': 226.0894, 'eval_samples_per_second': 1.07, 'eval_steps_per_second': 1.07, 'eval_rewards/chosen': -1.1071468591690063, 'eval_rewards/rejected': -1.064937949180603, 'eval_rewards/accuracies': 0.4834710657596588, 'eval_rewards/margins': -0.04220879450440407, 'eval_logps/rejected': -163.75697326660156, 'eval_logps/chosen': -160.08969116210938, 'eval_logits/rejected': 1.4516522884368896, 'eval_logits/chosen': 1.4476468563079834, 'epoch': 0.0, 'memory_allocated (GB)': 58.0, 'max_memory_allocated (GB)': 84.25, 'total_memory_available (GB)': 94.62}\n",
      " 10%|████                                    | 100/1000 [07:11<27:12,  1.81s/it]\n",
      "100%|█████████████████████████████████████████| 242/242 [03:44<00:00,  1.08it/s]\u001b[A\n",
      "{'loss': 0.8715, 'grad_norm': 6.96875, 'learning_rate': 0.0004998477067547739, 'rewards/chosen': -1.546875, 'rewards/rejected': -1.3984375, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -0.154296875, 'logps/rejected': -178.0, 'logps/chosen': -181.0, 'logits/rejected': 0.8695909380912781, 'logits/chosen': 0.7714802026748657, 'epoch': 0.0, 'memory_allocated (GB)': 58.04, 'max_memory_allocated (GB)': 84.25, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.9525, 'grad_norm': 2.59375, 'learning_rate': 0.0004993910125649561, 'rewards/chosen': -2.203125, 'rewards/rejected': -2.0, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': -0.1962890625, 'logps/rejected': -159.0, 'logps/chosen': -177.0, 'logits/rejected': -1.0777909755706787, 'logits/chosen': -1.1273458003997803, 'epoch': 0.0, 'memory_allocated (GB)': 58.12, 'max_memory_allocated (GB)': 84.25, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 6.5198, 'grad_norm': 51.5, 'learning_rate': 0.0004986304738420684, 'rewards/chosen': -16.5, 'rewards/rejected': -14.6875, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': -1.7890625, 'logps/rejected': -310.0, 'logps/chosen': -324.0, 'logits/rejected': -1.5263900756835938, 'logits/chosen': -1.5580247640609741, 'epoch': 0.0, 'memory_allocated (GB)': 58.17, 'max_memory_allocated (GB)': 84.25, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 5.9473, 'grad_norm': 0.0, 'learning_rate': 0.0004975670171853926, 'rewards/chosen': -19.375, 'rewards/rejected': -19.625, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 0.2353515625, 'logps/rejected': -366.0, 'logps/chosen': -344.0, 'logits/rejected': -1.9711577892303467, 'logits/chosen': -1.9745330810546875, 'epoch': 0.0, 'memory_allocated (GB)': 57.97, 'max_memory_allocated (GB)': 84.25, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.7882, 'grad_norm': 5.46875, 'learning_rate': 0.000496201938253052, 'rewards/chosen': -6.28125, 'rewards/rejected': -6.3125, 'rewards/accuracies': 0.5, 'rewards/margins': 0.0120849609375, 'logps/rejected': -216.0, 'logps/chosen': -218.0, 'logits/rejected': -1.6929823160171509, 'logits/chosen': -1.6995937824249268, 'epoch': 0.0, 'memory_allocated (GB)': 57.91, 'max_memory_allocated (GB)': 84.25, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.3406, 'grad_norm': 9.125, 'learning_rate': 0.0004945369001834514, 'rewards/chosen': -3.546875, 'rewards/rejected': -3.09375, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': -0.455078125, 'logps/rejected': -184.0, 'logps/chosen': -214.0, 'logits/rejected': -1.1850906610488892, 'logits/chosen': -1.2661997079849243, 'epoch': 0.0, 'memory_allocated (GB)': 58.03, 'max_memory_allocated (GB)': 84.25, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.9714, 'grad_norm': 3.671875, 'learning_rate': 0.0004925739315689991, 'rewards/chosen': -2.90625, 'rewards/rejected': -2.84375, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -0.06494140625, 'logps/rejected': -161.0, 'logps/chosen': -194.0, 'logits/rejected': -0.8744559288024902, 'logits/chosen': -0.9217845797538757, 'epoch': 0.0, 'memory_allocated (GB)': 58.05, 'max_memory_allocated (GB)': 84.25, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.7262, 'grad_norm': 3.609375, 'learning_rate': 0.0004903154239845797, 'rewards/chosen': -2.296875, 'rewards/rejected': -2.703125, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 0.396484375, 'logps/rejected': -162.0, 'logps/chosen': -140.0, 'logits/rejected': -0.711490273475647, 'logits/chosen': -0.6439458131790161, 'epoch': 0.0, 'memory_allocated (GB)': 57.92, 'max_memory_allocated (GB)': 84.4, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.9544, 'grad_norm': 6.6875, 'learning_rate': 0.0004877641290737884, 'rewards/chosen': -2.53125, 'rewards/rejected': -2.4375, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': -0.10302734375, 'logps/rejected': -170.0, 'logps/chosen': -172.0, 'logits/rejected': -1.468820333480835, 'logits/chosen': -1.483284831047058, 'epoch': 0.0, 'memory_allocated (GB)': 58.02, 'max_memory_allocated (GB)': 84.4, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.0948, 'grad_norm': 8.8125, 'learning_rate': 0.0004849231551964771, 'rewards/chosen': -2.515625, 'rewards/rejected': -2.15625, 'rewards/accuracies': 0.375, 'rewards/margins': -0.359375, 'logps/rejected': -161.0, 'logps/chosen': -177.0, 'logits/rejected': -1.3821958303451538, 'logits/chosen': -1.445933222770691, 'epoch': 0.0, 'memory_allocated (GB)': 58.11, 'max_memory_allocated (GB)': 84.4, 'total_memory_available (GB)': 94.62}\n",
      " 20%|████████                                | 200/1000 [10:15<23:26,  1.76s/it]\n",
      "  0%|                                                   | 0/242 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▎                                          | 2/242 [00:00<00:33,  7.15it/s]\u001b[A\n",
      "  1%|▌                                          | 3/242 [00:00<00:47,  5.02it/s]\u001b[A\n",
      "  2%|▋                                          | 4/242 [00:00<00:54,  4.37it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▏| 237/242 [01:05<00:01,  3.61it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▎| 238/242 [01:05<00:01,  3.61it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▍| 239/242 [01:06<00:00,  3.61it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▋| 240/242 [01:06<00:00,  3.61it/s]\u001b[A\n",
      "100%|████████████████████████████████████████▊| 241/242 [01:06<00:00,  3.61it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8780840635299683, 'eval_runtime': 67.3334, 'eval_samples_per_second': 3.594, 'eval_steps_per_second': 3.594, 'eval_rewards/chosen': -2.1157028675079346, 'eval_rewards/rejected': -2.179022789001465, 'eval_rewards/accuracies': 0.4917355477809906, 'eval_rewards/margins': 0.06331922858953476, 'eval_logps/rejected': -174.89781188964844, 'eval_logps/chosen': -170.1752471923828, 'eval_logits/rejected': -1.1227915287017822, 'eval_logits/chosen': -1.120614767074585, 'epoch': 0.0, 'memory_allocated (GB)': 58.11, 'max_memory_allocated (GB)': 84.4, 'total_memory_available (GB)': 94.62}\n",
      " 20%|████████                                | 200/1000 [11:22<23:26,  1.76s/it]\n",
      "100%|█████████████████████████████████████████| 242/242 [01:07<00:00,  3.27it/s]\u001b[A\n",
      "{'loss': 0.8632, 'grad_norm': 3.828125, 'learning_rate': 0.00048179596364169685, 'rewards/chosen': -1.9765625, 'rewards/rejected': -1.90625, 'rewards/accuracies': 0.3499999940395355, 'rewards/margins': -0.0712890625, 'logps/rejected': -172.0, 'logps/chosen': -169.0, 'logits/rejected': -0.8864170908927917, 'logits/chosen': -0.9166609644889832, 'epoch': 0.0, 'memory_allocated (GB)': 58.0, 'max_memory_allocated (GB)': 84.4, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.0567, 'grad_norm': 10.9375, 'learning_rate': 0.0004783863644106502, 'rewards/chosen': -2.453125, 'rewards/rejected': -2.1875, 'rewards/accuracies': 0.32499998807907104, 'rewards/margins': -0.275390625, 'logps/rejected': -165.0, 'logps/chosen': -180.0, 'logits/rejected': -1.0008035898208618, 'logits/chosen': -1.0579793453216553, 'epoch': 0.0, 'memory_allocated (GB)': 58.05, 'max_memory_allocated (GB)': 84.4, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.2334, 'grad_norm': 6.1875, 'learning_rate': 0.00047469851157479177, 'rewards/chosen': -2.640625, 'rewards/rejected': -2.25, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': -0.400390625, 'logps/rejected': -181.0, 'logps/chosen': -199.0, 'logits/rejected': -1.4074361324310303, 'logits/chosen': -1.4201416969299316, 'epoch': 0.0, 'memory_allocated (GB)': 57.99, 'max_memory_allocated (GB)': 84.4, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.8107, 'grad_norm': 4.03125, 'learning_rate': 0.00047073689821473173, 'rewards/chosen': -2.25, 'rewards/rejected': -2.359375, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 0.11328125, 'logps/rejected': -169.0, 'logps/chosen': -169.0, 'logits/rejected': -1.734126091003418, 'logits/chosen': -1.7482115030288696, 'epoch': 0.0, 'memory_allocated (GB)': 58.06, 'max_memory_allocated (GB)': 84.46, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.8555, 'grad_norm': 9.0, 'learning_rate': 0.00046650635094610973, 'rewards/chosen': -2.96875, 'rewards/rejected': -3.1875, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 0.234375, 'logps/rejected': -189.0, 'logps/chosen': -163.0, 'logits/rejected': -2.214953660964966, 'logits/chosen': -2.1690514087677, 'epoch': 0.0, 'memory_allocated (GB)': 57.97, 'max_memory_allocated (GB)': 84.46, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.0436, 'grad_norm': 5.5625, 'learning_rate': 0.00046201202403910646, 'rewards/chosen': -3.34375, 'rewards/rejected': -3.15625, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': -0.18359375, 'logps/rejected': -173.0, 'logps/chosen': -167.0, 'logits/rejected': -2.0724809169769287, 'logits/chosen': -2.108891248703003, 'epoch': 0.0, 'memory_allocated (GB)': 57.95, 'max_memory_allocated (GB)': 84.46, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.9237, 'grad_norm': 7.3125, 'learning_rate': 0.00045725939313876043, 'rewards/chosen': -2.90625, 'rewards/rejected': -2.71875, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -0.18359375, 'logps/rejected': -172.0, 'logps/chosen': -215.0, 'logits/rejected': -2.113438844680786, 'logits/chosen': -2.2052345275878906, 'epoch': 0.0, 'memory_allocated (GB)': 58.16, 'max_memory_allocated (GB)': 84.46, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.8463, 'grad_norm': 4.875, 'learning_rate': 0.0004522542485937369, 'rewards/chosen': -2.71875, 'rewards/rejected': -2.65625, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': -0.0673828125, 'logps/rejected': -191.0, 'logps/chosen': -186.0, 'logits/rejected': -1.6251510381698608, 'logits/chosen': -1.6844947338104248, 'epoch': 0.0, 'memory_allocated (GB)': 58.03, 'max_memory_allocated (GB)': 84.46, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.11, 'grad_norm': 10.625, 'learning_rate': 0.00044700268840168044, 'rewards/chosen': -2.515625, 'rewards/rejected': -2.140625, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -0.37109375, 'logps/rejected': -159.0, 'logps/chosen': -195.0, 'logits/rejected': -1.9476276636123657, 'logits/chosen': -2.041109561920166, 'epoch': 0.0, 'memory_allocated (GB)': 57.99, 'max_memory_allocated (GB)': 84.46, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.1295, 'grad_norm': 5.90625, 'learning_rate': 0.0004415111107797445, 'rewards/chosen': -2.6875, 'rewards/rejected': -2.296875, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -0.39453125, 'logps/rejected': -154.0, 'logps/chosen': -170.0, 'logits/rejected': -2.5525765419006348, 'logits/chosen': -2.604302406311035, 'epoch': 0.0, 'memory_allocated (GB)': 57.9, 'max_memory_allocated (GB)': 84.46, 'total_memory_available (GB)': 94.62}\n",
      " 30%|████████████                            | 300/1000 [14:21<20:41,  1.77s/it]\n",
      "  0%|                                                   | 0/242 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▎                                          | 2/242 [00:00<00:33,  7.17it/s]\u001b[A\n",
      "  1%|▌                                          | 3/242 [00:00<00:47,  5.05it/s]\u001b[A\n",
      "  2%|▋                                          | 4/242 [00:00<00:54,  4.36it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▎| 238/242 [01:05<00:01,  3.63it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▍| 239/242 [01:06<00:00,  3.62it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▋| 240/242 [01:06<00:00,  3.62it/s]\u001b[A\n",
      "100%|████████████████████████████████████████▊| 241/242 [01:06<00:00,  3.62it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.9279903173446655, 'eval_runtime': 67.3447, 'eval_samples_per_second': 3.593, 'eval_steps_per_second': 3.593, 'eval_rewards/chosen': -2.7810001373291016, 'eval_rewards/rejected': -2.7754597663879395, 'eval_rewards/accuracies': 0.4958677589893341, 'eval_rewards/margins': -0.005540406331419945, 'eval_logps/rejected': -180.8621826171875, 'eval_logps/chosen': -176.82823181152344, 'eval_logits/rejected': -2.791909694671631, 'eval_logits/chosen': -2.7787837982177734, 'epoch': 0.0, 'memory_allocated (GB)': 57.9, 'max_memory_allocated (GB)': 84.46, 'total_memory_available (GB)': 94.62}\n",
      " 30%|████████████                            | 300/1000 [15:28<20:41,  1.77s/it]\n",
      "100%|█████████████████████████████████████████| 242/242 [01:07<00:00,  3.63it/s]\u001b[A\n",
      "{'loss': 1.1525, 'grad_norm': 13.3125, 'learning_rate': 0.00043578620636934855, 'rewards/chosen': -3.109375, 'rewards/rejected': -2.859375, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -0.23828125, 'logps/rejected': -160.0, 'logps/chosen': -171.0, 'logits/rejected': -2.759234666824341, 'logits/chosen': -2.8075053691864014, 'epoch': 0.0, 'memory_allocated (GB)': 58.01, 'max_memory_allocated (GB)': 84.46, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.5141, 'grad_norm': 5.40625, 'learning_rate': 0.0004298349500846628, 'rewards/chosen': -4.40625, 'rewards/rejected': -3.578125, 'rewards/accuracies': 0.30000001192092896, 'rewards/margins': -0.828125, 'logps/rejected': -187.0, 'logps/chosen': -207.0, 'logits/rejected': -3.0121827125549316, 'logits/chosen': -3.0820436477661133, 'epoch': 0.0, 'memory_allocated (GB)': 58.06, 'max_memory_allocated (GB)': 84.49, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.5723, 'grad_norm': 1.4453125, 'learning_rate': 0.00042366459261474935, 'rewards/chosen': -5.125, 'rewards/rejected': -5.09375, 'rewards/accuracies': 0.5, 'rewards/margins': -0.0172119140625, 'logps/rejected': -228.0, 'logps/chosen': -212.0, 'logits/rejected': -3.058359384536743, 'logits/chosen': -3.056661605834961, 'epoch': 0.0, 'memory_allocated (GB)': 58.01, 'max_memory_allocated (GB)': 84.49, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.2186, 'grad_norm': 15.25, 'learning_rate': 0.0004172826515897146, 'rewards/chosen': -3.328125, 'rewards/rejected': -3.234375, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': -0.09326171875, 'logps/rejected': -169.0, 'logps/chosen': -189.0, 'logits/rejected': -2.7854464054107666, 'logits/chosen': -2.8197808265686035, 'epoch': 0.0, 'memory_allocated (GB)': 58.02, 'max_memory_allocated (GB)': 84.49, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.3645, 'grad_norm': 9.4375, 'learning_rate': 0.0004106969024216348, 'rewards/chosen': -3.640625, 'rewards/rejected': -3.046875, 'rewards/accuracies': 0.375, 'rewards/margins': -0.58203125, 'logps/rejected': -170.0, 'logps/chosen': -194.0, 'logits/rejected': -2.6109251976013184, 'logits/chosen': -2.684229612350464, 'epoch': 0.0, 'memory_allocated (GB)': 58.07, 'max_memory_allocated (GB)': 84.49, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.0089, 'grad_norm': 7.25, 'learning_rate': 0.00040391536883141455, 'rewards/chosen': -2.4375, 'rewards/rejected': -2.375, 'rewards/accuracies': 0.375, 'rewards/margins': -0.06787109375, 'logps/rejected': -165.0, 'logps/chosen': -174.0, 'logits/rejected': -2.613081693649292, 'logits/chosen': -2.6402363777160645, 'epoch': 0.0, 'memory_allocated (GB)': 58.15, 'max_memory_allocated (GB)': 84.49, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.7507, 'grad_norm': 12.5, 'learning_rate': 0.0003969463130731183, 'rewards/chosen': -3.5, 'rewards/rejected': -2.65625, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -0.83984375, 'logps/rejected': -166.0, 'logps/chosen': -172.0, 'logits/rejected': -2.5787806510925293, 'logits/chosen': -2.620136260986328, 'epoch': 0.0, 'memory_allocated (GB)': 58.01, 'max_memory_allocated (GB)': 84.49, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.3501, 'grad_norm': 2.359375, 'learning_rate': 0.0003897982258676867, 'rewards/chosen': -3.25, 'rewards/rejected': -2.65625, 'rewards/accuracies': 0.375, 'rewards/margins': -0.5859375, 'logps/rejected': -166.0, 'logps/chosen': -184.0, 'logits/rejected': -2.1103532314300537, 'logits/chosen': -2.148502826690674, 'epoch': 0.0, 'memory_allocated (GB)': 58.04, 'max_memory_allocated (GB)': 84.49, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 3.2353, 'grad_norm': 0.0, 'learning_rate': 0.00038247981605830125, 'rewards/chosen': -8.125, 'rewards/rejected': -6.1875, 'rewards/accuracies': 0.30000001192092896, 'rewards/margins': -1.921875, 'logps/rejected': -207.0, 'logps/chosen': -264.0, 'logits/rejected': -2.4669301509857178, 'logits/chosen': -2.36448335647583, 'epoch': 0.0, 'memory_allocated (GB)': 58.11, 'max_memory_allocated (GB)': 84.51, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.8714, 'grad_norm': 9.4375, 'learning_rate': 0.000375, 'rewards/chosen': -3.875, 'rewards/rejected': -3.234375, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -0.6328125, 'logps/rejected': -167.0, 'logps/chosen': -197.0, 'logits/rejected': -2.217480182647705, 'logits/chosen': -2.230217218399048, 'epoch': 0.0, 'memory_allocated (GB)': 58.03, 'max_memory_allocated (GB)': 84.51, 'total_memory_available (GB)': 94.62}\n",
      " 40%|████████████████                        | 400/1000 [18:33<17:29,  1.75s/it]\n",
      "  0%|                                                   | 0/242 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▎                                          | 2/242 [00:00<00:33,  7.24it/s]\u001b[A\n",
      "  1%|▌                                          | 3/242 [00:00<00:46,  5.10it/s]\u001b[A\n",
      "  2%|▋                                          | 4/242 [00:00<00:53,  4.43it/s]\u001b[A\n",
      "  2%|▉                                          | 5/242 [00:01<00:57,  4.11it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▎| 238/242 [01:05<00:01,  3.64it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▍| 239/242 [01:06<00:00,  3.64it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▋| 240/242 [01:06<00:00,  3.30it/s]\u001b[A\n",
      "100%|████████████████████████████████████████▊| 241/242 [01:06<00:00,  3.42it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.82951819896698, 'eval_runtime': 67.2122, 'eval_samples_per_second': 3.601, 'eval_steps_per_second': 3.601, 'eval_rewards/chosen': -1.958084225654602, 'eval_rewards/rejected': -2.07253360748291, 'eval_rewards/accuracies': 0.5165289044380188, 'eval_rewards/margins': 0.11444982141256332, 'eval_logps/rejected': -173.83291625976562, 'eval_logps/chosen': -168.5990753173828, 'eval_logits/rejected': -2.1750364303588867, 'eval_logits/chosen': -2.170382261276245, 'epoch': 0.0, 'memory_allocated (GB)': 58.04, 'max_memory_allocated (GB)': 84.51, 'total_memory_available (GB)': 94.62}\n",
      " 40%|████████████████                        | 400/1000 [19:40<17:29,  1.75s/it]\n",
      "100%|█████████████████████████████████████████| 242/242 [01:06<00:00,  3.48it/s]\u001b[A\n",
      "{'loss': 0.8558, 'grad_norm': 6.3125, 'learning_rate': 0.0003673678906964727, 'rewards/chosen': -1.9921875, 'rewards/rejected': -1.953125, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': -0.037109375, 'logps/rejected': -173.0, 'logps/chosen': -161.0, 'logits/rejected': -2.1129672527313232, 'logits/chosen': -2.12776780128479, 'epoch': 0.0, 'memory_allocated (GB)': 57.96, 'max_memory_allocated (GB)': 84.51, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.9229, 'grad_norm': 8.0625, 'learning_rate': 0.00035959278669726934, 'rewards/chosen': -2.109375, 'rewards/rejected': -2.28125, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 0.1640625, 'logps/rejected': -184.0, 'logps/chosen': -162.0, 'logits/rejected': -1.8762266635894775, 'logits/chosen': -1.8594245910644531, 'epoch': 0.0, 'memory_allocated (GB)': 57.93, 'max_memory_allocated (GB)': 84.51, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.8759, 'grad_norm': 13.5, 'learning_rate': 0.0003516841607689501, 'rewards/chosen': -2.03125, 'rewards/rejected': -2.203125, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 0.162109375, 'logps/rejected': -193.0, 'logps/chosen': -198.0, 'logits/rejected': -1.7379621267318726, 'logits/chosen': -1.7581241130828857, 'epoch': 0.0, 'memory_allocated (GB)': 57.97, 'max_memory_allocated (GB)': 84.51, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.9388, 'grad_norm': 3.734375, 'learning_rate': 0.00034365164835397803, 'rewards/chosen': -2.578125, 'rewards/rejected': -2.515625, 'rewards/accuracies': 0.5, 'rewards/margins': -0.07177734375, 'logps/rejected': -162.0, 'logps/chosen': -192.0, 'logits/rejected': -2.2429869174957275, 'logits/chosen': -2.333019733428955, 'epoch': 0.0, 'memory_allocated (GB)': 58.03, 'max_memory_allocated (GB)': 84.51, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.0153, 'grad_norm': 2.015625, 'learning_rate': 0.0003355050358314172, 'rewards/chosen': -3.40625, 'rewards/rejected': -3.1875, 'rewards/accuracies': 0.375, 'rewards/margins': -0.2197265625, 'logps/rejected': -177.0, 'logps/chosen': -176.0, 'logits/rejected': -2.3312830924987793, 'logits/chosen': -2.4267868995666504, 'epoch': 0.0, 'memory_allocated (GB)': 58.01, 'max_memory_allocated (GB)': 84.51, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.8383, 'grad_norm': 11.1875, 'learning_rate': 0.00032725424859373687, 'rewards/chosen': -3.59375, 'rewards/rejected': -4.03125, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 0.427734375, 'logps/rejected': -188.0, 'logps/chosen': -195.0, 'logits/rejected': -2.169434070587158, 'logits/chosen': -2.259542226791382, 'epoch': 0.0, 'memory_allocated (GB)': 58.03, 'max_memory_allocated (GB)': 84.51, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.3048, 'grad_norm': 2.234375, 'learning_rate': 0.0003189093389542498, 'rewards/chosen': -3.796875, 'rewards/rejected': -3.46875, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -0.32421875, 'logps/rejected': -166.0, 'logps/chosen': -192.0, 'logits/rejected': -2.0632083415985107, 'logits/chosen': -2.1692488193511963, 'epoch': 0.0, 'memory_allocated (GB)': 58.05, 'max_memory_allocated (GB)': 84.51, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.946, 'grad_norm': 2.359375, 'learning_rate': 0.0003104804738999169, 'rewards/chosen': -3.375, 'rewards/rejected': -3.65625, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 0.271484375, 'logps/rejected': -205.0, 'logps/chosen': -206.0, 'logits/rejected': -2.567960023880005, 'logits/chosen': -2.635286808013916, 'epoch': 0.0, 'memory_allocated (GB)': 58.01, 'max_memory_allocated (GB)': 84.51, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.2636, 'grad_norm': 7.9375, 'learning_rate': 0.0003019779227044398, 'rewards/chosen': -4.21875, 'rewards/rejected': -4.0, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': -0.2109375, 'logps/rejected': -194.0, 'logps/chosen': -216.0, 'logits/rejected': -2.697084903717041, 'logits/chosen': -2.7482964992523193, 'epoch': 0.0, 'memory_allocated (GB)': 58.03, 'max_memory_allocated (GB)': 84.51, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.2976, 'grad_norm': 19.375, 'learning_rate': 0.00029341204441673266, 'rewards/chosen': -4.65625, 'rewards/rejected': -4.1875, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': -0.4609375, 'logps/rejected': -181.0, 'logps/chosen': -217.0, 'logits/rejected': -2.815830945968628, 'logits/chosen': -2.9118940830230713, 'epoch': 0.0, 'memory_allocated (GB)': 57.98, 'max_memory_allocated (GB)': 84.51, 'total_memory_available (GB)': 94.62}\n",
      " 50%|████████████████████                    | 500/1000 [22:47<15:03,  1.81s/it]\n",
      "  0%|                                                   | 0/242 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▎                                          | 2/242 [00:00<00:33,  7.25it/s]\u001b[A\n",
      "  1%|▌                                          | 3/242 [00:00<00:46,  5.11it/s]\u001b[A\n",
      "  2%|▋                                          | 4/242 [00:00<00:53,  4.43it/s]\u001b[A\n",
      "  2%|▉                                          | 5/242 [00:01<00:57,  4.16it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▎| 238/242 [01:05<00:01,  3.63it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▍| 239/242 [01:06<00:00,  3.63it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▋| 240/242 [01:06<00:00,  3.63it/s]\u001b[A\n",
      "100%|████████████████████████████████████████▊| 241/242 [01:06<00:00,  3.63it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.0776444673538208, 'eval_runtime': 67.1096, 'eval_samples_per_second': 3.606, 'eval_steps_per_second': 3.606, 'eval_rewards/chosen': -4.443456649780273, 'eval_rewards/rejected': -4.684968948364258, 'eval_rewards/accuracies': 0.557851254940033, 'eval_rewards/margins': 0.24151185154914856, 'eval_logps/rejected': -199.95726013183594, 'eval_logps/chosen': -193.45278930664062, 'eval_logits/rejected': -2.875114679336548, 'eval_logits/chosen': -2.8963401317596436, 'epoch': 0.0, 'memory_allocated (GB)': 57.99, 'max_memory_allocated (GB)': 84.51, 'total_memory_available (GB)': 94.62}\n",
      " 50%|████████████████████                    | 500/1000 [23:54<15:03,  1.81s/it]\n",
      "100%|█████████████████████████████████████████| 242/242 [01:06<00:00,  3.64it/s]\u001b[A\n",
      "{'loss': 1.0659, 'grad_norm': 11.9375, 'learning_rate': 0.00028479327524001636, 'rewards/chosen': -4.65625, 'rewards/rejected': -4.9375, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 0.2734375, 'logps/rejected': -205.0, 'logps/chosen': -200.0, 'logits/rejected': -3.0772781372070312, 'logits/chosen': -3.0723605155944824, 'epoch': 0.0, 'memory_allocated (GB)': 58.12, 'max_memory_allocated (GB)': 84.51, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.9264, 'grad_norm': 8.8125, 'learning_rate': 0.0002761321158169134, 'rewards/chosen': -4.6875, 'rewards/rejected': -4.78125, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 0.0966796875, 'logps/rejected': -213.0, 'logps/chosen': -218.0, 'logits/rejected': -3.2814712524414062, 'logits/chosen': -3.377331495285034, 'epoch': 0.0, 'memory_allocated (GB)': 58.04, 'max_memory_allocated (GB)': 84.51, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.9909, 'grad_norm': 1.1484375, 'learning_rate': 0.0002674391184360313, 'rewards/chosen': -3.90625, 'rewards/rejected': -3.890625, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': -0.015869140625, 'logps/rejected': -193.0, 'logps/chosen': -203.0, 'logits/rejected': -3.2421669960021973, 'logits/chosen': -3.2861266136169434, 'epoch': 0.0, 'memory_allocated (GB)': 58.14, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.7258, 'grad_norm': 4.8125, 'learning_rate': 0.0002587248741756253, 'rewards/chosen': -3.3125, 'rewards/rejected': -3.9375, 'rewards/accuracies': 0.6499999761581421, 'rewards/margins': 0.62109375, 'logps/rejected': -211.0, 'logps/chosen': -214.0, 'logits/rejected': -3.350510835647583, 'logits/chosen': -3.4007675647735596, 'epoch': 0.0, 'memory_allocated (GB)': 58.12, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.9933, 'grad_norm': 6.46875, 'learning_rate': 0.00025, 'rewards/chosen': -3.1875, 'rewards/rejected': -3.015625, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -0.171875, 'logps/rejected': -176.0, 'logps/chosen': -183.0, 'logits/rejected': -3.326261043548584, 'logits/chosen': -3.351348400115967, 'epoch': 0.0, 'memory_allocated (GB)': 57.94, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.6925, 'grad_norm': 0.51171875, 'learning_rate': 0.00024127512582437484, 'rewards/chosen': -2.6875, 'rewards/rejected': -3.109375, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 0.423828125, 'logps/rejected': -169.0, 'logps/chosen': -175.0, 'logits/rejected': -3.2996883392333984, 'logits/chosen': -3.362539291381836, 'epoch': 0.0, 'memory_allocated (GB)': 58.09, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.7756, 'grad_norm': 3.4375, 'learning_rate': 0.00023256088156396867, 'rewards/chosen': -2.359375, 'rewards/rejected': -2.671875, 'rewards/accuracies': 0.6499999761581421, 'rewards/margins': 0.3125, 'logps/rejected': -168.0, 'logps/chosen': -181.0, 'logits/rejected': -3.04118013381958, 'logits/chosen': -3.095252513885498, 'epoch': 0.0, 'memory_allocated (GB)': 58.07, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.0765, 'grad_norm': 9.0, 'learning_rate': 0.00022386788418308668, 'rewards/chosen': -2.46875, 'rewards/rejected': -2.5625, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 0.0869140625, 'logps/rejected': -173.0, 'logps/chosen': -180.0, 'logits/rejected': -3.0018491744995117, 'logits/chosen': -2.977712631225586, 'epoch': 0.0, 'memory_allocated (GB)': 57.94, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.1638, 'grad_norm': 11.125, 'learning_rate': 0.0002152067247599837, 'rewards/chosen': -2.640625, 'rewards/rejected': -2.59375, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -0.041259765625, 'logps/rejected': -167.0, 'logps/chosen': -204.0, 'logits/rejected': -3.077449083328247, 'logits/chosen': -3.1609127521514893, 'epoch': 0.0, 'memory_allocated (GB)': 58.02, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.1382, 'grad_norm': 6.875, 'learning_rate': 0.00020658795558326743, 'rewards/chosen': -2.734375, 'rewards/rejected': -2.484375, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': -0.2431640625, 'logps/rejected': -176.0, 'logps/chosen': -177.0, 'logits/rejected': -3.2294113636016846, 'logits/chosen': -3.201101779937744, 'epoch': 0.0, 'memory_allocated (GB)': 57.98, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      " 60%|████████████████████████                | 600/1000 [27:00<11:59,  1.80s/it]\n",
      "  0%|                                                   | 0/242 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▎                                          | 2/242 [00:00<00:33,  7.20it/s]\u001b[A\n",
      "  1%|▌                                          | 3/242 [00:00<00:47,  5.07it/s]\u001b[A\n",
      "  2%|▋                                          | 4/242 [00:00<00:54,  4.40it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▎| 238/242 [01:05<00:01,  3.64it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▍| 239/242 [01:05<00:00,  3.64it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▋| 240/242 [01:06<00:00,  3.63it/s]\u001b[A\n",
      "100%|████████████████████████████████████████▊| 241/242 [01:06<00:00,  3.63it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.0630854368209839, 'eval_runtime': 66.9292, 'eval_samples_per_second': 3.616, 'eval_steps_per_second': 3.616, 'eval_rewards/chosen': -2.406477451324463, 'eval_rewards/rejected': -2.4175949096679688, 'eval_rewards/accuracies': 0.5123966932296753, 'eval_rewards/margins': 0.01111720222979784, 'eval_logps/rejected': -177.28350830078125, 'eval_logps/chosen': -173.08297729492188, 'eval_logits/rejected': -3.224292278289795, 'eval_logits/chosen': -3.232712984085083, 'epoch': 0.0, 'memory_allocated (GB)': 57.99, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      " 60%|████████████████████████                | 600/1000 [28:07<11:59,  1.80s/it]\n",
      "100%|█████████████████████████████████████████| 242/242 [01:06<00:00,  3.64it/s]\u001b[A\n",
      "{'loss': 0.7747, 'grad_norm': 2.328125, 'learning_rate': 0.0001980220772955602, 'rewards/chosen': -2.390625, 'rewards/rejected': -2.71875, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 0.328125, 'logps/rejected': -179.0, 'logps/chosen': -187.0, 'logits/rejected': -3.3428337574005127, 'logits/chosen': -3.389685869216919, 'epoch': 0.0, 'memory_allocated (GB)': 57.96, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.1771, 'grad_norm': 9.0625, 'learning_rate': 0.0001895195261000831, 'rewards/chosen': -3.28125, 'rewards/rejected': -3.109375, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': -0.166015625, 'logps/rejected': -162.0, 'logps/chosen': -182.0, 'logits/rejected': -3.3973262310028076, 'logits/chosen': -3.4348793029785156, 'epoch': 0.0, 'memory_allocated (GB)': 58.09, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.2726, 'grad_norm': 0.6953125, 'learning_rate': 0.00018109066104575022, 'rewards/chosen': -3.296875, 'rewards/rejected': -2.90625, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': -0.400390625, 'logps/rejected': -162.0, 'logps/chosen': -199.0, 'logits/rejected': -3.507704973220825, 'logits/chosen': -3.5714468955993652, 'epoch': 0.0, 'memory_allocated (GB)': 57.98, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.4863, 'grad_norm': 12.4375, 'learning_rate': 0.00017274575140626317, 'rewards/chosen': -3.515625, 'rewards/rejected': -3.03125, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -0.490234375, 'logps/rejected': -166.0, 'logps/chosen': -177.0, 'logits/rejected': -3.4395813941955566, 'logits/chosen': -3.5029892921447754, 'epoch': 0.0, 'memory_allocated (GB)': 57.94, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.0033, 'grad_norm': 2.375, 'learning_rate': 0.00016449496416858284, 'rewards/chosen': -3.15625, 'rewards/rejected': -3.515625, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 0.359375, 'logps/rejected': -188.0, 'logps/chosen': -188.0, 'logits/rejected': -3.4566962718963623, 'logits/chosen': -3.5083465576171875, 'epoch': 0.0, 'memory_allocated (GB)': 58.04, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.1575, 'grad_norm': 6.0625, 'learning_rate': 0.00015634835164602198, 'rewards/chosen': -3.109375, 'rewards/rejected': -3.0625, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': -0.035400390625, 'logps/rejected': -181.0, 'logps/chosen': -174.0, 'logits/rejected': -3.587156295776367, 'logits/chosen': -3.6152560710906982, 'epoch': 0.0, 'memory_allocated (GB)': 58.14, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.3447, 'grad_norm': 7.03125, 'learning_rate': 0.00014831583923105, 'rewards/chosen': -3.609375, 'rewards/rejected': -3.140625, 'rewards/accuracies': 0.375, 'rewards/margins': -0.462890625, 'logps/rejected': -169.0, 'logps/chosen': -179.0, 'logits/rejected': -3.5242271423339844, 'logits/chosen': -3.605236530303955, 'epoch': 0.0, 'memory_allocated (GB)': 58.03, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.0671, 'grad_norm': 5.5625, 'learning_rate': 0.00014040721330273062, 'rewards/chosen': -3.296875, 'rewards/rejected': -3.265625, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': -0.033203125, 'logps/rejected': -197.0, 'logps/chosen': -186.0, 'logits/rejected': -3.5989747047424316, 'logits/chosen': -3.6336867809295654, 'epoch': 0.0, 'memory_allocated (GB)': 58.13, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.7654, 'grad_norm': 0.1806640625, 'learning_rate': 0.00013263210930352737, 'rewards/chosen': -3.0625, 'rewards/rejected': -3.8125, 'rewards/accuracies': 0.675000011920929, 'rewards/margins': 0.765625, 'logps/rejected': -200.0, 'logps/chosen': -159.0, 'logits/rejected': -3.66412353515625, 'logits/chosen': -3.6514365673065186, 'epoch': 0.0, 'memory_allocated (GB)': 57.93, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.5558, 'grad_norm': 17.25, 'learning_rate': 0.00012500000000000006, 'rewards/chosen': -4.21875, 'rewards/rejected': -3.734375, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': -0.48046875, 'logps/rejected': -182.0, 'logps/chosen': -234.0, 'logits/rejected': -3.4770874977111816, 'logits/chosen': -3.5855209827423096, 'epoch': 0.0, 'memory_allocated (GB)': 58.02, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      " 70%|████████████████████████████            | 700/1000 [31:10<08:39,  1.73s/it]\n",
      "  0%|                                                   | 0/242 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▎                                          | 2/242 [00:00<00:33,  7.24it/s]\u001b[A\n",
      "  1%|▌                                          | 3/242 [00:00<00:46,  5.10it/s]\u001b[A\n",
      "  2%|▋                                          | 4/242 [00:00<00:53,  4.42it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▏| 237/242 [01:05<00:01,  3.57it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▎| 238/242 [01:06<00:01,  3.27it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▍| 239/242 [01:06<00:00,  3.36it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▋| 240/242 [01:06<00:00,  3.43it/s]\u001b[A\n",
      "100%|████████████████████████████████████████▊| 241/242 [01:07<00:00,  3.48it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.1480220556259155, 'eval_runtime': 67.6897, 'eval_samples_per_second': 3.575, 'eval_steps_per_second': 3.575, 'eval_rewards/chosen': -3.278740882873535, 'eval_rewards/rejected': -3.296098232269287, 'eval_rewards/accuracies': 0.5123966932296753, 'eval_rewards/margins': 0.01735701784491539, 'eval_logps/rejected': -186.06854248046875, 'eval_logps/chosen': -181.80563354492188, 'eval_logits/rejected': -3.413057804107666, 'eval_logits/chosen': -3.421283006668091, 'epoch': 0.0, 'memory_allocated (GB)': 58.04, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      " 70%|████████████████████████████            | 700/1000 [32:18<08:39,  1.73s/it]\n",
      "100%|█████████████████████████████████████████| 242/242 [01:07<00:00,  3.52it/s]\u001b[A\n",
      "{'loss': 0.8713, 'grad_norm': 10.75, 'learning_rate': 0.0001175201839416988, 'rewards/chosen': -2.96875, 'rewards/rejected': -3.734375, 'rewards/accuracies': 0.625, 'rewards/margins': 0.7734375, 'logps/rejected': -203.0, 'logps/chosen': -153.0, 'logits/rejected': -3.5305206775665283, 'logits/chosen': -3.4211249351501465, 'epoch': 0.0, 'memory_allocated (GB)': 58.12, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.5807, 'grad_norm': 7.875, 'learning_rate': 0.00011020177413231333, 'rewards/chosen': -3.875, 'rewards/rejected': -3.046875, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -0.828125, 'logps/rejected': -176.0, 'logps/chosen': -200.0, 'logits/rejected': -3.364226818084717, 'logits/chosen': -3.366299867630005, 'epoch': 0.0, 'memory_allocated (GB)': 57.9, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.1833, 'grad_norm': 14.625, 'learning_rate': 0.00010305368692688174, 'rewards/chosen': -3.34375, 'rewards/rejected': -3.234375, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': -0.10546875, 'logps/rejected': -180.0, 'logps/chosen': -202.0, 'logits/rejected': -3.4202613830566406, 'logits/chosen': -3.4769577980041504, 'epoch': 0.0, 'memory_allocated (GB)': 58.02, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.0218, 'grad_norm': 7.125, 'learning_rate': 9.608463116858542e-05, 'rewards/chosen': -2.890625, 'rewards/rejected': -3.21875, 'rewards/accuracies': 0.625, 'rewards/margins': 0.33203125, 'logps/rejected': -184.0, 'logps/chosen': -176.0, 'logits/rejected': -3.402204990386963, 'logits/chosen': -3.4213531017303467, 'epoch': 0.0, 'memory_allocated (GB)': 58.0, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.2228, 'grad_norm': 7.15625, 'learning_rate': 8.930309757836516e-05, 'rewards/chosen': -2.984375, 'rewards/rejected': -2.671875, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': -0.30859375, 'logps/rejected': -160.0, 'logps/chosen': -184.0, 'logits/rejected': -3.4301223754882812, 'logits/chosen': -3.447242259979248, 'epoch': 0.0, 'memory_allocated (GB)': 57.99, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.0436, 'grad_norm': 26.5, 'learning_rate': 8.271734841028553e-05, 'rewards/chosen': -3.28125, 'rewards/rejected': -3.46875, 'rewards/accuracies': 0.4749999940395355, 'rewards/margins': 0.1923828125, 'logps/rejected': -185.0, 'logps/chosen': -191.0, 'logits/rejected': -3.39573335647583, 'logits/chosen': -3.4753623008728027, 'epoch': 0.0, 'memory_allocated (GB)': 58.1, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.9866, 'grad_norm': 6.9375, 'learning_rate': 7.633540738525066e-05, 'rewards/chosen': -2.890625, 'rewards/rejected': -2.796875, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -0.1015625, 'logps/rejected': -169.0, 'logps/chosen': -193.0, 'logits/rejected': -3.439638614654541, 'logits/chosen': -3.4720420837402344, 'epoch': 0.0, 'memory_allocated (GB)': 57.93, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.8757, 'grad_norm': 6.4375, 'learning_rate': 7.016504991533726e-05, 'rewards/chosen': -2.796875, 'rewards/rejected': -3.078125, 'rewards/accuracies': 0.625, 'rewards/margins': 0.28125, 'logps/rejected': -160.0, 'logps/chosen': -162.0, 'logits/rejected': -3.359898090362549, 'logits/chosen': -3.364140748977661, 'epoch': 0.0, 'memory_allocated (GB)': 58.08, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.0603, 'grad_norm': 1.6640625, 'learning_rate': 6.421379363065141e-05, 'rewards/chosen': -3.0, 'rewards/rejected': -2.8125, 'rewards/accuracies': 0.5, 'rewards/margins': -0.1796875, 'logps/rejected': -189.0, 'logps/chosen': -194.0, 'logits/rejected': -3.2786948680877686, 'logits/chosen': -3.3617730140686035, 'epoch': 0.0, 'memory_allocated (GB)': 58.04, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.9789, 'grad_norm': 6.0625, 'learning_rate': 5.848888922025553e-05, 'rewards/chosen': -3.0, 'rewards/rejected': -3.15625, 'rewards/accuracies': 0.5, 'rewards/margins': 0.150390625, 'logps/rejected': -183.0, 'logps/chosen': -179.0, 'logits/rejected': -3.409376859664917, 'logits/chosen': -3.427539348602295, 'epoch': 0.0, 'memory_allocated (GB)': 58.02, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      " 80%|████████████████████████████████        | 800/1000 [35:20<05:51,  1.76s/it]\n",
      "  0%|                                                   | 0/242 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▎                                          | 2/242 [00:00<00:33,  7.17it/s]\u001b[A\n",
      "  1%|▌                                          | 3/242 [00:00<00:47,  5.07it/s]\u001b[A\n",
      "  2%|▋                                          | 4/242 [00:00<00:54,  4.41it/s]\u001b[A\n",
      " 98%|███████████████████████████████████████▉ | 236/242 [01:05<00:01,  3.70it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▏| 237/242 [01:05<00:01,  3.68it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▎| 238/242 [01:05<00:01,  3.64it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▍| 239/242 [01:06<00:00,  3.33it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▋| 240/242 [01:06<00:00,  3.42it/s]\u001b[A\n",
      "100%|████████████████████████████████████████▊| 241/242 [01:06<00:00,  3.48it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.0260080099105835, 'eval_runtime': 67.3802, 'eval_samples_per_second': 3.592, 'eval_steps_per_second': 3.592, 'eval_rewards/chosen': -2.850233554840088, 'eval_rewards/rejected': -2.9461798667907715, 'eval_rewards/accuracies': 0.5330578684806824, 'eval_rewards/margins': 0.09594563394784927, 'eval_logps/rejected': -182.5693817138672, 'eval_logps/chosen': -177.52056884765625, 'eval_logits/rejected': -3.269294261932373, 'eval_logits/chosen': -3.2790369987487793, 'epoch': 0.0, 'memory_allocated (GB)': 58.03, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      " 80%|████████████████████████████████        | 800/1000 [36:28<05:51,  1.76s/it]\n",
      "100%|█████████████████████████████████████████| 242/242 [01:07<00:00,  3.53it/s]\u001b[A\n",
      "{'loss': 1.1889, 'grad_norm': 5.5, 'learning_rate': 5.299731159831953e-05, 'rewards/chosen': -3.21875, 'rewards/rejected': -3.046875, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -0.1708984375, 'logps/rejected': -166.0, 'logps/chosen': -187.0, 'logits/rejected': -3.2622196674346924, 'logits/chosen': -3.3288612365722656, 'epoch': 0.0, 'memory_allocated (GB)': 58.0, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.9916, 'grad_norm': 9.5, 'learning_rate': 4.7745751406263163e-05, 'rewards/chosen': -3.046875, 'rewards/rejected': -3.1875, 'rewards/accuracies': 0.5, 'rewards/margins': 0.142578125, 'logps/rejected': -173.0, 'logps/chosen': -183.0, 'logits/rejected': -3.287707567214966, 'logits/chosen': -3.3332648277282715, 'epoch': 0.0, 'memory_allocated (GB)': 57.88, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.8903, 'grad_norm': 8.6875, 'learning_rate': 4.274060686123959e-05, 'rewards/chosen': -2.96875, 'rewards/rejected': -3.25, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 0.26953125, 'logps/rejected': -183.0, 'logps/chosen': -167.0, 'logits/rejected': -3.2222189903259277, 'logits/chosen': -3.2273051738739014, 'epoch': 0.0, 'memory_allocated (GB)': 57.97, 'max_memory_allocated (GB)': 84.55, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.851, 'grad_norm': 5.6875, 'learning_rate': 3.798797596089351e-05, 'rewards/chosen': -2.875, 'rewards/rejected': -3.3125, 'rewards/accuracies': 0.625, 'rewards/margins': 0.447265625, 'logps/rejected': -189.0, 'logps/chosen': -164.0, 'logits/rejected': -3.2475380897521973, 'logits/chosen': -3.2281436920166016, 'epoch': 0.0, 'memory_allocated (GB)': 57.91, 'max_memory_allocated (GB)': 84.56, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.0489, 'grad_norm': 14.75, 'learning_rate': 3.3493649053890325e-05, 'rewards/chosen': -3.296875, 'rewards/rejected': -3.3125, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': 0.004791259765625, 'logps/rejected': -196.0, 'logps/chosen': -212.0, 'logits/rejected': -3.206080198287964, 'logits/chosen': -3.22369647026062, 'epoch': 0.0, 'memory_allocated (GB)': 57.94, 'max_memory_allocated (GB)': 84.56, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.0063, 'grad_norm': 2.953125, 'learning_rate': 2.9263101785268254e-05, 'rewards/chosen': -3.3125, 'rewards/rejected': -3.375, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 0.06884765625, 'logps/rejected': -177.0, 'logps/chosen': -186.0, 'logits/rejected': -3.245976686477661, 'logits/chosen': -3.222647190093994, 'epoch': 0.0, 'memory_allocated (GB)': 58.03, 'max_memory_allocated (GB)': 84.56, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.1229, 'grad_norm': 2.953125, 'learning_rate': 2.5301488425208295e-05, 'rewards/chosen': -3.25, 'rewards/rejected': -3.03125, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': -0.2138671875, 'logps/rejected': -193.0, 'logps/chosen': -211.0, 'logits/rejected': -3.3368430137634277, 'logits/chosen': -3.383526563644409, 'epoch': 0.0, 'memory_allocated (GB)': 58.1, 'max_memory_allocated (GB)': 84.56, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.2294, 'grad_norm': 2.921875, 'learning_rate': 2.1613635589349755e-05, 'rewards/chosen': -3.640625, 'rewards/rejected': -3.453125, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -0.181640625, 'logps/rejected': -192.0, 'logps/chosen': -198.0, 'logits/rejected': -3.336742877960205, 'logits/chosen': -3.3807902336120605, 'epoch': 0.0, 'memory_allocated (GB)': 57.94, 'max_memory_allocated (GB)': 84.56, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.1625, 'grad_norm': 6.84375, 'learning_rate': 1.8204036358303172e-05, 'rewards/chosen': -3.4375, 'rewards/rejected': -3.375, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': -0.059814453125, 'logps/rejected': -202.0, 'logps/chosen': -181.0, 'logits/rejected': -3.219587802886963, 'logits/chosen': -3.2249844074249268, 'epoch': 0.0, 'memory_allocated (GB)': 57.99, 'max_memory_allocated (GB)': 84.56, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.9858, 'grad_norm': 21.25, 'learning_rate': 1.5076844803522921e-05, 'rewards/chosen': -2.6875, 'rewards/rejected': -3.171875, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 0.484375, 'logps/rejected': -186.0, 'logps/chosen': -158.0, 'logits/rejected': -3.247533082962036, 'logits/chosen': -3.166923999786377, 'epoch': 0.0, 'memory_allocated (GB)': 58.07, 'max_memory_allocated (GB)': 84.56, 'total_memory_available (GB)': 94.62}\n",
      " 90%|████████████████████████████████████    | 900/1000 [39:32<02:57,  1.77s/it]\n",
      "  0%|                                                   | 0/242 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▎                                          | 2/242 [00:00<00:33,  7.20it/s]\u001b[A\n",
      "  1%|▌                                          | 3/242 [00:00<00:47,  5.07it/s]\u001b[A\n",
      "  2%|▋                                          | 4/242 [00:00<00:54,  4.40it/s]\u001b[A\n",
      "  2%|▉                                          | 5/242 [00:01<00:58,  4.08it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▎| 238/242 [01:06<00:01,  3.66it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▍| 239/242 [01:06<00:00,  3.65it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▋| 240/242 [01:06<00:00,  3.64it/s]\u001b[A\n",
      "100%|████████████████████████████████████████▊| 241/242 [01:06<00:00,  3.64it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.038029670715332, 'eval_runtime': 67.4038, 'eval_samples_per_second': 3.59, 'eval_steps_per_second': 3.59, 'eval_rewards/chosen': -3.0389232635498047, 'eval_rewards/rejected': -3.1633553504943848, 'eval_rewards/accuracies': 0.5206611752510071, 'eval_rewards/margins': 0.1244320198893547, 'eval_logps/rejected': -184.74111938476562, 'eval_logps/chosen': -179.40745544433594, 'eval_logits/rejected': -3.2186317443847656, 'eval_logits/chosen': -3.228569984436035, 'epoch': 0.0, 'memory_allocated (GB)': 58.07, 'max_memory_allocated (GB)': 84.56, 'total_memory_available (GB)': 94.62}\n",
      " 90%|████████████████████████████████████    | 900/1000 [40:39<02:57,  1.77s/it]\n",
      "100%|█████████████████████████████████████████| 242/242 [01:07<00:00,  3.64it/s]\u001b[A\n",
      "{'loss': 1.132, 'grad_norm': 11.6875, 'learning_rate': 1.2235870926211617e-05, 'rewards/chosen': -2.953125, 'rewards/rejected': -2.75, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -0.1953125, 'logps/rejected': -170.0, 'logps/chosen': -178.0, 'logits/rejected': -3.296631336212158, 'logits/chosen': -3.3509318828582764, 'epoch': 0.0, 'memory_allocated (GB)': 58.02, 'max_memory_allocated (GB)': 84.56, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.1058, 'grad_norm': 5.65625, 'learning_rate': 9.684576015420277e-06, 'rewards/chosen': -3.0625, 'rewards/rejected': -3.0625, 'rewards/accuracies': 0.550000011920929, 'rewards/margins': 0.00469970703125, 'logps/rejected': -154.0, 'logps/chosen': -170.0, 'logits/rejected': -3.2076478004455566, 'logits/chosen': -3.2459053993225098, 'epoch': 0.0, 'memory_allocated (GB)': 58.05, 'max_memory_allocated (GB)': 84.56, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.9584, 'grad_norm': 4.15625, 'learning_rate': 7.426068431000882e-06, 'rewards/chosen': -2.71875, 'rewards/rejected': -2.96875, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 0.23828125, 'logps/rejected': -166.0, 'logps/chosen': -183.0, 'logits/rejected': -3.179865837097168, 'logits/chosen': -3.247718095779419, 'epoch': 0.0, 'memory_allocated (GB)': 58.11, 'max_memory_allocated (GB)': 84.56, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.1535, 'grad_norm': 0.431640625, 'learning_rate': 5.463099816548578e-06, 'rewards/chosen': -3.703125, 'rewards/rejected': -3.78125, 'rewards/accuracies': 0.5, 'rewards/margins': 0.0732421875, 'logps/rejected': -205.0, 'logps/chosen': -186.0, 'logits/rejected': -3.2828547954559326, 'logits/chosen': -3.257310152053833, 'epoch': 0.0, 'memory_allocated (GB)': 58.1, 'max_memory_allocated (GB)': 84.56, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.1165, 'grad_norm': 2.328125, 'learning_rate': 3.798061746947995e-06, 'rewards/chosen': -3.1875, 'rewards/rejected': -3.28125, 'rewards/accuracies': 0.5, 'rewards/margins': 0.0947265625, 'logps/rejected': -184.0, 'logps/chosen': -168.0, 'logits/rejected': -3.3345093727111816, 'logits/chosen': -3.334965229034424, 'epoch': 0.0, 'memory_allocated (GB)': 58.01, 'max_memory_allocated (GB)': 84.56, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.2264, 'grad_norm': 11.875, 'learning_rate': 2.4329828146074094e-06, 'rewards/chosen': -3.328125, 'rewards/rejected': -2.921875, 'rewards/accuracies': 0.42500001192092896, 'rewards/margins': -0.40625, 'logps/rejected': -155.0, 'logps/chosen': -193.0, 'logits/rejected': -3.2423133850097656, 'logits/chosen': -3.2769787311553955, 'epoch': 0.0, 'memory_allocated (GB)': 58.14, 'max_memory_allocated (GB)': 84.56, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.9468, 'grad_norm': 6.5625, 'learning_rate': 1.3695261579316775e-06, 'rewards/chosen': -2.96875, 'rewards/rejected': -2.96875, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 0.00616455078125, 'logps/rejected': -185.0, 'logps/chosen': -179.0, 'logits/rejected': -3.3335444927215576, 'logits/chosen': -3.2954070568084717, 'epoch': 0.0, 'memory_allocated (GB)': 57.99, 'max_memory_allocated (GB)': 84.56, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.7225, 'grad_norm': 1.7109375, 'learning_rate': 6.089874350439506e-07, 'rewards/chosen': -2.703125, 'rewards/rejected': -3.296875, 'rewards/accuracies': 0.5249999761581421, 'rewards/margins': 0.58203125, 'logps/rejected': -188.0, 'logps/chosen': -178.0, 'logits/rejected': -3.185652256011963, 'logits/chosen': -3.171804189682007, 'epoch': 0.0, 'memory_allocated (GB)': 58.09, 'max_memory_allocated (GB)': 84.56, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 1.4298, 'grad_norm': 8.625, 'learning_rate': 1.5229324522605948e-07, 'rewards/chosen': -3.25, 'rewards/rejected': -2.703125, 'rewards/accuracies': 0.4000000059604645, 'rewards/margins': -0.5390625, 'logps/rejected': -155.0, 'logps/chosen': -195.0, 'logits/rejected': -3.1911988258361816, 'logits/chosen': -3.268292188644409, 'epoch': 0.0, 'memory_allocated (GB)': 58.11, 'max_memory_allocated (GB)': 84.56, 'total_memory_available (GB)': 94.62}\n",
      "{'loss': 0.9355, 'grad_norm': 13.25, 'learning_rate': 0.0, 'rewards/chosen': -3.1875, 'rewards/rejected': -3.28125, 'rewards/accuracies': 0.574999988079071, 'rewards/margins': 0.09912109375, 'logps/rejected': -172.0, 'logps/chosen': -186.0, 'logits/rejected': -3.357576847076416, 'logits/chosen': -3.3542118072509766, 'epoch': 0.0, 'memory_allocated (GB)': 58.12, 'max_memory_allocated (GB)': 84.56, 'total_memory_available (GB)': 94.62}\n",
      "100%|███████████████████████████████████████| 1000/1000 [43:42<00:00,  1.78s/it]\n",
      "  0%|                                                   | 0/242 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▎                                          | 2/242 [00:00<00:33,  7.24it/s]\u001b[A\n",
      "  1%|▌                                          | 3/242 [00:00<00:46,  5.10it/s]\u001b[A\n",
      "  2%|▋                                          | 4/242 [00:00<00:53,  4.42it/s]\u001b[A\n",
      "  2%|▉                                          | 5/242 [00:01<00:57,  4.10it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▍| 239/242 [01:06<00:00,  3.64it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▋| 240/242 [01:06<00:00,  3.64it/s]\u001b[A\n",
      "100%|████████████████████████████████████████▊| 241/242 [01:06<00:00,  3.64it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.0373610258102417, 'eval_runtime': 67.1236, 'eval_samples_per_second': 3.605, 'eval_steps_per_second': 3.605, 'eval_rewards/chosen': -3.035933494567871, 'eval_rewards/rejected': -3.1632187366485596, 'eval_rewards/accuracies': 0.5289255976676941, 'eval_rewards/margins': 0.12728533148765564, 'eval_logps/rejected': -184.73974609375, 'eval_logps/chosen': -179.37754821777344, 'eval_logits/rejected': -3.211592674255371, 'eval_logits/chosen': -3.221644639968872, 'epoch': 0.0, 'memory_allocated (GB)': 58.13, 'max_memory_allocated (GB)': 84.56, 'total_memory_available (GB)': 94.62}\n",
      "100%|███████████████████████████████████████| 1000/1000 [44:50<00:00,  1.78s/it]\n",
      "100%|█████████████████████████████████████████| 242/242 [01:06<00:00,  3.64it/s]\u001b[A\n",
      "{'train_runtime': 2696.1118, 'train_samples_per_second': 1.484, 'train_steps_per_second': 0.371, 'train_loss': 1.1785692186355592, 'epoch': 0.0, 'memory_allocated (GB)': 58.13, 'max_memory_allocated (GB)': 84.56, 'total_memory_available (GB)': 94.62}\n",
      "100%|███████████████████████████████████████| 1000/1000 [44:56<00:00,  2.70s/it]\n"
     ]
    }
   ],
   "source": [
    "!python dpo.py \\\n",
    "    --model_name_or_path=\"sft/final_merged_checkpoint\" \\\n",
    "    --tokenizer_name_or_path=meta-llama/Llama-2-7b-hf \\\n",
    "    --lora_target_modules \"q_proj\" \"v_proj\" \"k_proj\" \"out_proj\" \"fc_in\" \"fc_out\" \"wte\" \\\n",
    "    --output_dir=\"dpo\" \\\n",
    "    --report_to=none"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3683be1b",
   "metadata": {},
   "source": [
    "#### Merging the adaptors\n",
    "\n",
    "To merge the adaptors into the base model we can use the merge_peft_adapter.py helper script that comes with TRL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "350dcfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:462: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:319: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:00<00:00,  2.28it/s]\n"
     ]
    }
   ],
   "source": [
    "!python merge_peft_adapter.py --base_model_name=\"meta-llama/Llama-2-7b-hf\" --adapter_model_name=\"dpo\" --output_name=\"stack-llama-2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d0ef89",
   "metadata": {},
   "source": [
    "which will also push the model to your HuggingFace hub account."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4375ad4",
   "metadata": {},
   "source": [
    "#### Running the model\n",
    "\n",
    "We can load the DPO-trained LoRA adaptors which were saved by the DPO training step and run it through the [text-generation example]([../text-generation/](https://github.com/huggingface/optimum-habana/tree/main/examples/text-generation))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8750d250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/optimum-habana/examples/text-generation\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:462: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:319: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:319: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:319: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "06/03/2024 22:12:34 - INFO - __main__ - Single-device run.\n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:00<00:00,  3.14it/s]\n",
      "============================= HABANA PT BRIDGE CONFIGURATION =========================== \n",
      " PT_HPU_LAZY_MODE = 1\n",
      " PT_RECIPE_CACHE_PATH = \n",
      " PT_CACHE_FOLDER_DELETE = 0\n",
      " PT_HPU_RECIPE_CACHE_CONFIG = \n",
      " PT_HPU_MAX_COMPOUND_OP_SIZE = 9223372036854775807\n",
      " PT_HPU_LAZY_ACC_PAR_MODE = 1\n",
      " PT_HPU_ENABLE_REFINE_DYNAMIC_SHAPES = 0\n",
      "---------------------------: System Configuration :---------------------------\n",
      "Num CPU Cores : 160\n",
      "CPU RAM       : 1056433764 KB\n",
      "------------------------------------------------------------------------------\n",
      "06/03/2024 22:12:41 - INFO - __main__ - Args: Namespace(device='hpu', model_name_or_path='../trl/stack-llama-2/', bf16=True, max_new_tokens=50, max_input_tokens=0, batch_size=1, warmup=3, n_iterations=5, local_rank=0, use_kv_cache=True, use_hpu_graphs=True, dataset_name=None, column_name=None, do_sample=True, num_beams=1, trim_logits=False, seed=27, profiling_warmup_steps=0, profiling_steps=0, prompt=['When I go to New York I always go see '], bad_words=None, force_words=None, peft_model=None, num_return_sequences=1, token=None, model_revision='main', attn_softmax_bf16=False, output_dir=None, bucket_size=-1, bucket_internal=False, dataset_max_samples=-1, limit_hpu_graphs=False, reuse_cache=False, verbose_workers=False, simulate_dyn_prompt=None, reduce_recompile=False, fp8=False, use_flash_attention=False, flash_attention_recompute=False, flash_attention_causal_mask=False, book_source=False, torch_compile=False, temperature=0.5, top_p=0.5, const_serialization_path=None, disk_offload=False, quant_config='', world_size=0, global_rank=0)\n",
      "06/03/2024 22:12:41 - INFO - __main__ - device: hpu, n_hpu: 0, bf16: True\n",
      "06/03/2024 22:12:41 - INFO - __main__ - Model initialization took 7.348s\n",
      "06/03/2024 22:12:41 - INFO - __main__ - Graph compilation...\n",
      "Warming up\n",
      "Warming up\n",
      "Warming up\n",
      "06/03/2024 22:12:44 - INFO - __main__ - Running generate...\n",
      "\n",
      "Input/outputs:\n",
      "input 1: ('When I go to New York I always go see ',)\n",
      "output 1: (\"When I go to New York I always go see 1 show. I saw 2 last time I was there. This time I only saw 1. I went to see the Broadway production of The Book of Mormon.\\nI've been a fan of South Park for a long time\",)\n",
      "\n",
      "\n",
      "Stats:\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "Throughput (including tokenization) = 126.41970690028455 tokens/second\n",
      "Number of HPU graphs                = 18\n",
      "Memory allocated                    = 12.68 GB\n",
      "Max memory allocated                = 12.68 GB\n",
      "Total memory available              = 94.62 GB\n",
      "Graph compilation duration          = 2.923220989003312 seconds\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%cd ~/optimum-habana/examples/text-generation/\n",
    "!python run_generation.py \\\n",
    "--model_name_or_path ../trl/stack-llama-2/ \\\n",
    "--use_hpu_graphs --use_kv_cache --batch_size 1 --bf16 --do_sample --max_new_tokens 50 \\\n",
    "--temperature 0.5 \\\n",
    "--top_p 0.5 \\\n",
    "--prompt \"When I go to New York I always go see \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae666d1-7e11-43fe-a73a-0f1edf047eb5",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "You now have access to all the Models in Model-References and Optimum-Habana repositories, you can start to look at other models.  Remember that all the models in these repositories are fully documented so they are easy to use.\n",
    "* To explore more models from the Model References, start [here](https://github.com/HabanaAI/Model-References).  \n",
    "* To run more examples using Hugging Face go [here](https://github.com/huggingface/optimum-habana?tab=readme-ov-file#validated-models).  \n",
    "* To migrate other models to Gaudi 2, refer to PyTorch Model Porting in the [documentation](https://docs.habana.ai/en/latest/PyTorch/PyTorch_Model_Porting/GPU_Migration_Toolkit/GPU_Migration_Toolkit.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ddf63e-263f-4de1-bed1-a959588b7b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
