{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68877607",
   "metadata": {},
   "source": [
    "Copyright (c) 2023 Habana Labs, Ltd. an Intel Company.  \n",
    "Copyright (c) 2017, Pytorch contributors All rights reserved.\n",
    "SPDX-License-Identifier: BSD-3-Clause\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16169a66",
   "metadata": {},
   "source": [
    "# Model Migration from GPU to the Intel&reg; Gaudi&reg; 2 AI Accelerator \n",
    "\n",
    "The GPU Migration toolkit simplifies migrating PyTorch models that run on GPU-based architecture to run on the Intel® Gaudi® AI accelerator. Rather than manually replacing Python API calls that have dependencies on GPU libraries with Gaudi-specific API calls, the toolkit automates this process so you can run your model with fewer modifications. \n",
    "\n",
    "The GPU Migration toolkit maps specific API calls from the Python libraries and modules listed below to the appropriate equivalents in the Intel Gaudi software:\n",
    "\n",
    "* torch.cuda  \n",
    "* Torch API with GPU related parameters. For example, torch.randn(device=”cuda”)  \n",
    "\n",
    "The toolkit does not optimize the performance of the model, so further modifications may be required. For more details, refer to Model Performance Optimization Guide.\n",
    "\n",
    "In this notebook we will demonstrate how to use the GPU Migration toolset on a ResNet50 model which is based on open source implementation of ResNet50.  \n",
    "\n",
    "Refer to the [GPU Migration Toolkit](https://docs.habana.ai/en/latest/PyTorch/PyTorch_Model_Porting/GPU_Migration_Toolkit/GPU_Migration_Toolkit.html) for more information.  \n",
    "\n",
    "In addition to this ResNet50 migration, there is a GPU Migration example on the Intel Gaudi GitHub page [here](https://github.com/HabanaAI/Model-References/tree/master/PyTorch/examples/gpu_migration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e904bd5",
   "metadata": {},
   "source": [
    "### Enabling the GPU Migration Toolkit Summary\n",
    "\n",
    "#### Set the library\n",
    "Import the habana_frameworks.torch.gpu_migration package at the beginning of the primary Python script (main.py, train.py, etc.):\n",
    "`import habana_frameworks.torch.gpu_migration`\n",
    "Alternatively, you can use PT_HPU_GPU_MIGRATION=1 environment variable when running the primary Python script (main.py, train.py, etc.): `PT_HPU_GPU_MIGRATION=1 $PYTHON main.py`\n",
    "\n",
    "#### Set the Mark Step\n",
    "Add mark_step(). In Lazy mode, mark_step() must be added in all training scripts right after loss.backward() and optimizer.step().\n",
    "\n",
    "`htcore.mark_step()`   Note that if your model is using torch.compile, this step is not needed. \n",
    "\n",
    "#### Running Migrated code and logging changes \n",
    "Make sure that any device selection argument passed to the script is configured as if the script is running on a GPU. For example, add --cuda or --device gpu in the runtime command of your model. This will guarantee that the GPU Migration toolkit accurately detects and migrates instructions.\n",
    "\n",
    "You can enable the logging feature, included in the GPU Migration toolkit, by setting the `GPU_MIGRATION_LOG_LEVEL` environment variable like this example:   \n",
    "`GPU_MIGRATION_LOG_LEVEL=3 PT_HPU_GPU_MIGRATION=1 $PYTHON main.py`\n",
    "\n",
    "#### For More Information\n",
    "For more information regarding the use and configuration of the GPU Migration Toolkit and its limitations, please refer to the documentation here (https://docs.habana.ai/en/latest/PyTorch/PyTorch_Model_Porting/GPU_Migration_Toolkit/GPU_Migration_Toolkit.htm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3302bbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with the `exit()` command to restart the Python kernel to ensure that there are no other processes holding the Intel Gaudi Accelerator as you start to run this notebook.  You will see a warning that the kernel has died, this is expected.\n",
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b787e14c-c88e-4dfa-ac00-8ea66065d209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#Enable PT_HPU_LAZY_MODE=1\n",
    "os.environ['PT_HPU_LAZY_MODE'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8666669b",
   "metadata": {},
   "source": [
    "#### Running the ResNet50 Example\n",
    "The remainder of the notebook will show how the tool works with the [ResNet50 example](https://github.com/HabanaAI/Model-References/tree/master/PyTorch/examples/gpu_migration) from the GPU Migration examples in Model-References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a26ab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/Gaudi-tutorials/PyTorch/Single_card_tutorials\n",
    "!git clone -b 1.21.0 https://github.com/habanaai/Model-References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64847f32",
   "metadata": {},
   "source": [
    "#### Navigate to the model example to begin the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2212748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/Gaudi-tutorials/PyTorch/Single_card_tutorials/Model-References/PyTorch/examples/gpu_migration/computer_vision/classification/torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a208072",
   "metadata": {},
   "source": [
    "#### Download dataset - OPTIONAL\n",
    "To fully run this example you can download the Tiny ImageNet dataset.  It needs to be organized according to PyTorch requirements, and as specified in the scripts of [imagenet-multiGPU.torch](https://github.com/soumith/imagenet-multiGPU.torch).   You do NOT need to have the dataset loaded to see the Migration steps and logging.    \n",
    "\n",
    "Please be patient, it takes a few minutes to unzip the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab18abd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --progress=bar:force http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
    "!chmod 600 ./tiny-imagenet-200.zip\n",
    "import os;os.makedirs(\"./datasets/\", exist_ok=True)\n",
    "!unzip -q ./tiny-imagenet-200.zip  -x \"tiny-imagenet-200/test*\" -d ./datasets/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aee70dc",
   "metadata": {},
   "source": [
    "#### Import GPU Migration Toolkit package and Habana Torch Library\n",
    "Look into train.py, you will see in the first line that we will load the `gpu.migration` library which is already included in the Intel Gaudi Software: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c905c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "cat -n train.py | head -n 21 | tail -n 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed748205",
   "metadata": {},
   "source": [
    "#### Placing mark_step()\n",
    "You will have to place the mark_step() function after the optimizer and loss.backward calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4e1aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "cat -n train.py | head -n 51 | tail -n 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea291f86",
   "metadata": {},
   "source": [
    "#### Run the following command to start multi-HPU training.\n",
    "We're now ready to run the training.  You will see that we've added the logging command at the beginning of the run: `GPU_MIGRATION_LOG_LEVEL=1` to show the output.   No other changes to the run command are needed.   As you see the training run is started, you will see the log files show exactly where the code changes are happening to change from GPU to Intel Gaudi, including the file name and location.\n",
    "\n",
    "Look for the [context] and [hpu_match] in the log file to see where the code is changed.\n",
    "\n",
    "Remember that if you do not download the dataset the training will not complete the execution, but you will see the GPU Migration changes in the logfile, this is the most important part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68b92d4",
   "metadata": {},
   "source": [
    "```bash\n",
    "GPU_MIGRATION_LOG_LEVEL=1 torchrun --nproc_per_node 1 train.py --batch-size=256 --model=resnet50 --device=cuda --data-path=\"./datasets/tiny-imagenet-200/\" --workers=8 --epochs=1 --opt=sgd --amp\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8607d65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!GPU_MIGRATION_LOG_LEVEL=1 torchrun --nproc_per_node 1 train.py --batch-size=256 --model=resnet50 --device=cuda --data-path=\"./datasets/tiny-imagenet-200/\" --workers=8 --epochs=1 --opt=sgd --amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "990520ab-cf50-42b3-aa80-41b7b265dc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please be sure to run this exit command to ensure that the resources running on Intel Gaudi are released \n",
    "exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
