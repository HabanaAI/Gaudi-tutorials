{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2023 Habana Labs, Ltd. an Intel Company.  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stable Diffusion Inference using Intel&reg; Gaudi&reg; AI Accelerator with PyTorch\n",
    "\n",
    "In this notebook we will demonstrate how you can run inference on the Intel Gaudi Accelerator with the stable-diffusion text-to-image generation model using Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with the `exit()` command to restart the Python kernel to ensure that there are no other processes holding the Intel Gaudi Accelerator as you start to run this notebook. You will see a warning that the kernel has died, this is expected.\n",
    "exit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will clone `optimum-habana` repository branch to this docker, let us change to the appropriate directory where our text-to-image generation script and model resides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~\n",
    "!git clone -b v1.15.0 https://github.com/huggingface/optimum-habana.git\n",
    "%cd ./optimum-habana/examples/stable-diffusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to install all the Python package dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --quiet -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready for image generation. Enter a prompt by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a prompt for image generation:  happy dogs on a bench\n"
     ]
    }
   ],
   "source": [
    "prompt = input(\"Enter a prompt for image generation: \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to generate images from your text prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python text_to_image_generation.py \\\n",
    "    --model_name_or_path stabilityai/stable-diffusion-2-1 \\\n",
    "    --prompts f'{prompt}' \\\n",
    "    --num_images_per_prompt 4 \\\n",
    "    --batch_size 7 \\\n",
    "    --height 768 \\\n",
    "    --width 768 \\\n",
    "    --image_save_dir /tmp/stable_diffusion_images \\\n",
    "    --use_habana \\\n",
    "    --use_hpu_graphs \\\n",
    "    --gaudi_config Habana/stable-diffusion-2 \\\n",
    "    --bf16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View results\n",
    "Run the below cell to view latest results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "filenames = sorted(glob.iglob(f'/tmp/stable_diffusion_images/image_*.png'))\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    image = Image.open(filename)\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please be sure to run this exit command to ensure that the resources running on Intel Gaudi are released \n",
    "exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "92265e7bf95517031b05ae8ffa1541004d740e0704a96d3b488bf9f3a9b868ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
