{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc00676b-8d19-4e0d-b61d-68ccc14c294d",
   "metadata": {},
   "source": [
    "Copyright (c) 2024 Habana Labs, Ltd. an Intel Company.\n",
    "\n",
    "##### Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License. You may obtain a copy of the License at https://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b714683-1b37-4048-bf91-2b5af1c18d40",
   "metadata": {},
   "source": [
    "# Intel® Gaudi® Accelerator Demo "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6db2bc-12ef-47a0-83f8-cfba2a8af03c",
   "metadata": {},
   "source": [
    "\n",
    "This document provides instructions on setting up the Intel Gaudi 2 AI accelerator Instance on the Intel® Developer Cloud or any on-premise Intel Gaudi Node. You will be running models from the Intel Gaudi software Model References and the Hugging Face Optimum Habana library.\n",
    "\n",
    "Please follow along with the [video](https://developer.habana.ai/intel-developer-cloud/) on our Developer Page to walk through the steps below.  This assumes that you have setup the latest Intel Gaudi PyTorch Docker image.\n",
    "\n",
    "To set up a multi-node instance with two or more Gaudi nodes, refer to Setting up Multiple Gaudi Nodes in the [Quick Start Guide Documentation](https://docs.habana.ai/en/latest/Intel_DevCloud_Quick_Start/Intel_DevCloud_Quick_Start.html#setting-up-multiple-gaudi-nodeshttps://docs.habana.ai/en/latest/Intel_DevCloud_Quick_Start/Intel_DevCloud_Quick_Start.html#setting-up-multiple-gaudi-nodes).  \n",
    "\n",
    "The first step is to install the Optimum Habana repository from GitHub and run the demo of Transformer Reinforcement Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37216139-611e-4b07-a90f-cb351f18b185",
   "metadata": {},
   "source": [
    "## Fine-tuning with Hugging Face Optimum Habana Library\n",
    "The Optimum Habana library is the interface between the Hugging Face Transformers and Diffusers libraries and the Gaudi 2 card. It provides a set of tools enabling easy model loading, training and inference on single and multi-card settings for different downstream tasks. The following example use the DPO and PPO pipeline to fine-tune a Llama 2 7B model.\n",
    "\n",
    "Follow the below steps to install the stable release from the Optimum Habana examples and library:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7420be01-fb88-466a-9fe7-87006340905f",
   "metadata": {},
   "source": [
    "1. Clone the Optimum-Habana project and check out the lastest stable release.  This repository gives access to the examples that are optimized for Intel Gaudi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07346c1a-1fea-4b62-8a79-760ca7a64073",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~\n",
    "!git clone https://github.com/huggingface/optimum-habana.git\n",
    "%cd optimum-habana\n",
    "!git checkout v1.11.1\n",
    "%cd ~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09ded02-2aa1-4725-b1fc-cf917e05d9aa",
   "metadata": {},
   "source": [
    "2. Install Optimum-Habana library. This will install the latest stable library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e35cc-0ea1-4205-ae70-323252169c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install optimum-habana==1.11.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db627879-a273-4914-8efd-68c9a81ebbb9",
   "metadata": {},
   "source": [
    "3. In order to use the DeepSpeed library on Intel Gaudi 2, install the Intel Gaudi DeepSpeed fork:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59e99a7-4db0-4519-b406-ccedee40796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/HabanaAI/DeepSpeed.git@1.15.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25f0546-e74c-4363-b443-a0f59504d973",
   "metadata": {},
   "source": [
    "The following example is based on the Optimum-Habana Text Classification task example. Change to the text-classification directory and install the additional SW requirements for this specific example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24537f40-8daa-4ac9-ad19-bf1cfaaf29f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/optimum-habana/examples/trl/\n",
    "!pip install -U -r requirements.txt\n",
    "!pip install datasets==2.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2bc05d-ae12-4e35-8e95-124b754d6d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli login --token <your_token_here>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f04ce10",
   "metadata": {},
   "source": [
    "### DPO Pipeline\n",
    "\n",
    "#### Training\n",
    "\n",
    "The following example is for the creation of StackLlaMa 2: a Stack exchange llama-v2-7b model. There are two main steps to the DPO training process:\n",
    "\n",
    "1. Supervised fine-tuning of the base llama-v2-7b model to create llama-v2-7b-se:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01698aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python sft.py \\\n",
    "    --model_name_or_path meta-llama/Llama-2-7b-hf \\\n",
    "    --output_dir=\"./sft\" \\\n",
    "    --max_steps=500 \\\n",
    "    --logging_steps=10 \\\n",
    "    --save_steps=100 \\\n",
    "    --per_device_train_batch_size=4 \\\n",
    "    --per_device_eval_batch_size=1 \\\n",
    "    --gradient_accumulation_steps=2 \\\n",
    "    --learning_rate=1e-4 \\\n",
    "    --lr_scheduler_type=\"cosine\" \\\n",
    "    --warmup_steps=100 \\\n",
    "    --weight_decay=0.05 \\\n",
    "    --optim=\"paged_adamw_32bit\" \\\n",
    "    --lora_target_modules \"q_proj\" \"v_proj\" \\\n",
    "    --bf16 \\\n",
    "    --remove_unused_columns=False \\\n",
    "    --run_name=\"sft_llama2\" \\\n",
    "    --report_to=none \\\n",
    "    --use_habana \\\n",
    "    --use_lazy_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d5158b",
   "metadata": {},
   "source": [
    "2. Run the DPO trainer using the model saved by the previous step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ec49d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python dpo.py \\\n",
    "    --model_name_or_path=\"sft/final_merged_checkpoint\" \\\n",
    "    --tokenizer_name_or_path=meta-llama/Llama-2-7b-hf \\\n",
    "    --lora_target_modules \"q_proj\" \"v_proj\" \"k_proj\" \"out_proj\" \"fc_in\" \"fc_out\" \"wte\" \\\n",
    "    --output_dir=\"dpo\" \\\n",
    "    --report_to=none"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3683be1b",
   "metadata": {},
   "source": [
    "#### Merging the adaptors\n",
    "\n",
    "To merge the adaptors into the base model we can use the merge_peft_adapter.py helper script that comes with TRL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350dcfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python merge_peft_adapter.py --base_model_name=\"meta-llama/Llama-2-7b-hf\" --adapter_model_name=\"dpo\" --output_name=\"stack-llama-2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d0ef89",
   "metadata": {},
   "source": [
    "which will also push the model to your HuggingFace hub account."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4375ad4",
   "metadata": {},
   "source": [
    "#### Running the model\n",
    "\n",
    "We can load the DPO-trained LoRA adaptors which were saved by the DPO training step and run it through the [text-generation example]([../text-generation/](https://github.com/huggingface/optimum-habana/tree/main/examples/text-generation))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8750d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/optimum-habana/examples/text-generation/\n",
    "!python run_generation.py \\\n",
    "--model_name_or_path ../trl/stack-llama-2/ \\\n",
    "--use_hpu_graphs --use_kv_cache --batch_size 1 --bf16 --max_new_tokens 100 \\\n",
    "--prompt \"Here is my prompt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b84768",
   "metadata": {},
   "source": [
    "## PPO Pipeline\n",
    "\n",
    "### Training\n",
    "\n",
    "The following example is for the creation of StackLlaMa 2: a Stack exchange llama-v2-7b model. There are three main steps to the PPO training process:\n",
    "\n",
    "1. Supervised fine-tuning of the base llama-v2-7b model to create llama-v2-7b-se:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b535c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/optimum-habana/examples/trl/\n",
    "!python sft.py \\\n",
    "    --model_name_or_path meta-llama/Llama-2-7b-hf \\\n",
    "    --output_dir=\"./sft\" \\\n",
    "    --max_steps=500 \\\n",
    "    --logging_steps=10 \\\n",
    "    --save_steps=100 \\\n",
    "    --per_device_train_batch_size=4 \\\n",
    "    --per_device_eval_batch_size=1 \\\n",
    "    --gradient_accumulation_steps=2 \\\n",
    "    --learning_rate=1e-4 \\\n",
    "    --lr_scheduler_type=\"cosine\" \\\n",
    "    --warmup_steps=100 \\\n",
    "    --weight_decay=0.05 \\\n",
    "    --optim=\"paged_adamw_32bit\" \\\n",
    "    --lora_target_modules \"q_proj\" \"v_proj\" \\\n",
    "    --bf16 \\\n",
    "    --remove_unused_columns=False \\\n",
    "    --run_name=\"sft_llama2\" \\\n",
    "    --report_to=none \\\n",
    "    --use_habana \\\n",
    "    --use_lazy_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af901d79",
   "metadata": {},
   "source": [
    "2. Reward modeling using dialog pairs from the SE dataset on the llama-v2-7b-se to create llama-v2-7b-se-rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c996fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python reward_modeling.py \\\n",
    "    --model_name=./sft/final_merged_checkpoint \\\n",
    "    --tokenizer_name=meta-llama/Llama-2-7b-hf \\\n",
    "    --output_dir=./rm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a8a3cf",
   "metadata": {},
   "source": [
    "To merge the adaptors into the base model we can use the `merge_peft_adapter.py` helper script that comes with TRL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cd64b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python merge_peft_adapter.py --base_model_name=\"meta-llama/Llama-2-7b-hf\" --adapter_model_name=\"rm\" --output_name=\"rm_merged_checkpoint\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886113a3",
   "metadata": {},
   "source": [
    "3. RL fine-tuning of llama-v2-7b-se with the llama-v2-7b-se-rm reward model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c617adbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ppo.py \\\n",
    "    --model_name=./sft/final_merged_checkpoint \\\n",
    "    --reward_model_name=./rm_merged_checkpoint \\\n",
    "    --tokenizer_name=meta-llama/Llama-2-7b-hf \\\n",
    "    --adafactor=False \\\n",
    "    --output_max_length=128 \\\n",
    "    --batch_size=8 \\\n",
    "    --gradient_accumulation_steps=8 \\\n",
    "    --batched_gen=True \\\n",
    "    --ppo_epochs=4 \\\n",
    "    --seed=0 \\\n",
    "    --learning_rate=1.4e-5 \\\n",
    "    --early_stopping=True \\\n",
    "    --output_dir=llama-se-rl-finetune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592ff46d",
   "metadata": {},
   "source": [
    "To merge the adaptors into the base model we can use the merge_peft_adapter.py helper script that comes with TRL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e963fd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python merge_peft_adapter.py --base_model_name=\"meta-llama/Llama-2-7b-hf\" --adapter_model_name=\"llama-se-rl-finetune\" --output_name=\"rl_merged_checkpoint\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a738413",
   "metadata": {},
   "source": [
    "### Running the model\n",
    "\n",
    "We can load the PPO-trained LoRA adaptors which were saved by the PPO training step and run it through the [text-generation example](https://github.com/huggingface/optimum-habana/tree/main/examples/text-generation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d2c1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/optimum-habana/examples/text-generation/\n",
    "!python run_generation.py \\\n",
    "--model_name_or_path ../trl/rl_merged_checkpoint/ \\\n",
    "--use_hpu_graphs --use_kv_cache --batch_size 1 --bf16 --max_new_tokens 100 \\\n",
    "--prompt \"Here is my prompt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae666d1-7e11-43fe-a73a-0f1edf047eb5",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "You now have access to all the Models in Model-References and Optimum-Habana repositories, you can start to look at other models.  Remember that all the models in these repositories are fully documented so they are easy to use.\n",
    "* To explore more models from the Model References, start [here](https://github.com/HabanaAI/Model-References).  \n",
    "* To run more examples using Hugging Face go [here](https://github.com/huggingface/optimum-habana?tab=readme-ov-file#validated-models).  \n",
    "* To migrate other models to Gaudi 2, refer to PyTorch Model Porting in the [documentation](https://docs.habana.ai/en/latest/PyTorch/PyTorch_Model_Porting/GPU_Migration_Toolkit/GPU_Migration_Toolkit.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
