{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2845ac96-162a-4f23-b6d3-0784d2589819",
   "metadata": {},
   "source": [
    "Copyright (c) 2024 Habana Labs, Ltd. an Intel Company.\n",
    "SPDX-License-Identifier: Apache-2.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a11a1f-e46b-438a-adbb-229c218965ab",
   "metadata": {},
   "source": [
    "## Using Hugging Face Pipelines on Intel&reg; Gaudi&reg; 2 - Image Classification\n",
    "This section showcases how to use the Hugging Face Transformers pipeline API to run an image classification task on Intel Gaudi.\n",
    "\n",
    "Hugging Face pipeline is an easy way to use models for inference. It is an object that abstract most of the complex code from the library, offering a simple API dedicated to several tasks. We choose \"image-classification\" task here.    \n",
    "Pipeline workflow is defined as a sequence of the following operations:\n",
    "\n",
    "        Input -> Preprocessing -> Model Inference -> Post-Processing (Task dependent) -> Output\n",
    "Pipeline supports running on CPU or GPU through the device argument. Users can specify device argument, for example, we set device=\"hpu\" in this case. \"adapt_transformers_to_gaudi\" will replace some Transformers' methods for equivalent methods optimized for Intel Gaudi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6d0201-fb5c-4996-868f-3b0c798cb3de",
   "metadata": {},
   "source": [
    "### The First step is Install the Hugging Face Optimum Habana Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e8d1c9-81d0-497f-8a38-7b727ab8eb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/Gaudi-tutorials/PyTorch/Hugging_Face_pipelines\n",
    "!pip install optimum-habana==1.15.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e081b70a-3a36-4f0b-bee9-28df30995c51",
   "metadata": {},
   "source": [
    "### Import all neccessary dependencies and call adapt_transformers_to_gaudi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d57c01-723c-478e-8ff5-357297e11827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import requests\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "from optimum.habana.transformers.modeling_utils import adapt_transformers_to_gaudi\n",
    "from habana_frameworks.torch.hpu import wrap_in_hpu_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15c2d25",
   "metadata": {},
   "source": [
    "The command below may be needed to modify the existing Hugging Face model classes to use the Intel Gaudi specific version of the model classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e47d68b-31d1-4b02-959f-f9e2af73d46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_transformers_to_gaudi()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb4070a-1afb-47e2-9d9f-f9760f81b124",
   "metadata": {},
   "source": [
    "### Download and initialize the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69dd8670-9aaa-493b-a859-c4c5718ac138",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    "image = PIL.Image.open(requests.get(image_url, stream=True, timeout=3000).raw).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2d61ad-64b5-46a3-a130-6e584ead6a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display image\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d47331-192b-4b1c-bb58-4e36da6815ad",
   "metadata": {},
   "source": [
    "### Setup the pipeline\n",
    "To setup the Hugging Face pipeline we set the following  \n",
    "1. choose the Hugging Face task: for this, we use **\"image-classification\"**\n",
    "2. Set the device to **\"hpu\"** which allows the pipeline to run on Intel Gaudi\n",
    "3. Choose model **\"google/vit-base-patch32-384\"** \n",
    "\n",
    "Finally we'll use the \"wrap_in_hpu_graph\" to wrap the module forward function with HPU Graphs. This wrapper captures, caches and replays the graph. More info [here](https://docs.habana.ai/en/latest/PyTorch/Inference_on_PyTorch/Inference_Using_HPU_Graphs.html).  \n",
    "\n",
    "You will see that the Intel Gaudi will build the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3affbc8-210a-4d7e-b77b-a161badc767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"image-classification\", model=\"google/vit-base-patch32-384\", device=\"hpu\")\n",
    "classifier.model = wrap_in_hpu_graph(classifier.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1cca52-6242-48c9-8359-c62141da79df",
   "metadata": {},
   "source": [
    "### Execute the Pipeline and Display the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8750fece-1fec-4eca-9a42-30162354d5e3",
   "metadata": {},
   "source": [
    "The following results in a multi-class classification prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93038d5e-812f-48a6-bc7e-449fece8e9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = classifier(images=image)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4261eaa7-5953-430c-b447-08a9ce55825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
