{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "208ee6a9-c3d5-4d5b-9102-33b6cab06aa6",
   "metadata": {},
   "source": [
    "Copyright (c) 2024 Habana Labs, Ltd. an Intel Company.\n",
    "SPDX-License-Identifier: Apache-2.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a14d34d-3cbe-4b29-bf7a-a5f7d6eb22b5",
   "metadata": {},
   "source": [
    "## Objective\n",
    "This tutorial will show the user how to run the Intel Gaudi Profiling tools: the habana_perf_tool and the Tensorboard plug-in on the Intel Gaudi 2 AI Accelerator, and the profiling trace viewer.  These tools will provide the user valueable optimization tips and information to modify any model for better performance.   Following these steps and using these tools can help you better understand some of the bottlenecks of your model.  For more information, please refer to the [Profiling](https://docs.habana.ai/en/latest/Profiling/index.html) section of the documentation for info on how to setup the profiler and the [Optimization Guide](https://docs.habana.ai/en/latest/PyTorch/Model_Optimization_PyTorch/index.html) for additional background on other optimization techniques.\n",
    "\n",
    "| Task                                 | Description                                             | Details                                         |\n",
    "|--------------------------------------|---------------------------------------------------------|-------------------------------------------------|\n",
    "| PyTorch Profiling with TensorBoard   | Obtains Gaudi-specific recommendations for performance using TensorBoard. | [Profiling with PyTorch](https://docs.habana.ai/en/latest/Profiling/Profiling_with_PyTorch.html#profiling-with-pytorch)        |\n",
    "| Review the PT_HPU_METRICS_FILE      | Looks for excessive re-compilations during runtime.     | [Runtime Environment Variables](https://docs.habana.ai/en/latest/PyTorch/Reference/Runtime_Flags.html#pytorch-runtime-flags)                   |                         \n",
    "| Profiling Trace Viewer               | Uses Perfetto to view traces.           |  [Getting Started with Intel Gaudi Profiler](https://docs.habana.ai/en/latest/Profiling/Intel_Gaudi_Profiling/Getting_Started_with_Profiler.html#getting-started-with-profiler)                      |                         \n",
    "| Model Logging                        | Sets ENABLE_CONSOLE to set Logging for debug and analysis. | [Runtime Environment Variables](https://docs.habana.ai/en/latest/PyTorch/Reference/Runtime_Flags.html#pytorch-runtime-flags)                |                         \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c50df7f-7e0f-44cd-a4e4-32d5d1219dd0",
   "metadata": {},
   "source": [
    "### Initial Setup\n",
    "To run the this jupyter notebook and the Tensorboard viewer, set the appropriate ports for access when you ssh into the Intel Gaudi 2 node. you need to ensure that the following ports are open:\n",
    "* 8888 (for running this jupyter notebook)\n",
    "* 6006 (for running Tensorboard)    \n",
    "\n",
    "Do to this, you need to add the following in your overall ssh commmand when connecting to the Intel Gaudi Node:\n",
    "\n",
    "`ssh -L 8888:localhost:8888 -L 6006:localhost:6006 .... `\n",
    "\n",
    "We start with an Intel Gaudi PyTorch Docker image and run this notebook.   For this example, we'll be using the [Swin Transformer](https://huggingface.co/microsoft/swin-base-patch4-window7-224-in22k) model from the Hugging Face Repository running on Hugging Face's Optimum-Habana library.  So the first step is to load the Optimum-Habana library and model repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bdc37b-0715-4caf-be4c-644ea0aa521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~\n",
    "!git clone -b v1.15.0 https://github.com/huggingface/optimum-habana.git\n",
    "!pip install optimum-habana==1.15.0\n",
    "!pip install pickleshare ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec63423",
   "metadata": {},
   "source": [
    "We now will go into the image-classification task and load the specfic requirements for the task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d301b6c1-f975-45f6-893c-13885ef9d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/optimum-habana/examples/image-classification\n",
    "!pip install --quiet -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57faeecd-5853-47d7-b148-ab327048447d",
   "metadata": {},
   "source": [
    "### Running the Model\n",
    "Now that the model is loaded, we'll run the model and look for the trace files for analysis. \n",
    "\n",
    "For this model script we can see the profiling set in the utils.py. \n",
    "For other models not in optimum-habana, users can refer to [Profiling_with_PyTorch](https://docs.habana.ai/en/latest/Profiling/Profiling_with_PyTorch.html) to setup profiling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48df403-cee4-4898-a4a6-5432d9cc58ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "cat -n ../../optimum/habana/utils.py | head -n 313 | tail -n 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a07d2b-f089-435a-b346-50b2eb82b8ca",
   "metadata": {},
   "source": [
    "Run Model to collect trace file (unoptimized)\n",
    "Swin Transformer is a model that capably serves as a general-purpose backbone for computer vision. run_image_classification.py is a script that showcases how to fine-tune Swin Transformer on HPUs.\n",
    "\n",
    "Notice the torch profiler specific commands:\n",
    "\n",
    "- `--profiling_warmup_steps 10` - profiler will wait for warmup steps\n",
    "- `--profiling_steps 3` - records for the next active steps  \n",
    "                             \n",
    "The collected trace files will be saved to ./hpu_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031de875-5f20-4893-af32-5ce9451afe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_image_classification.py \\\n",
    "    --model_name_or_path microsoft/swin-base-patch4-window7-224-in22k \\\n",
    "    --dataset_name cifar10 \\\n",
    "    --output_dir /tmp/outputs/ \\\n",
    "    --remove_unused_columns False \\\n",
    "    --image_column_name img \\\n",
    "    --do_train \\\n",
    "    --learning_rate 3e-5 \\\n",
    "    --num_train_epochs 2 \\\n",
    "    --per_device_train_batch_size 64 \\\n",
    "    --evaluation_strategy no \\\n",
    "    --save_strategy no \\\n",
    "    --load_best_model_at_end False \\\n",
    "    --save_total_limit 3 \\\n",
    "    --seed 1337 \\\n",
    "    --use_habana \\\n",
    "    --use_lazy_mode \\\n",
    "    --use_hpu_graphs_for_training \\\n",
    "    --gaudi_config_name Habana/swin \\\n",
    "    --throughput_warmup_steps 3 \\\n",
    "    --bf16 \\\n",
    "    --report_to none \\\n",
    "    --overwrite_output_dir \\\n",
    "    --ignore_mismatched_sizes \\\n",
    "    --profiling_warmup_steps 10 \\\n",
    "    --profiling_steps 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23106fe-e911-4e67-9c8f-4ad8d587408e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd hpu_profile\n",
    "%ls -al"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21347a9a",
   "metadata": {},
   "source": [
    "### Reviewing the Details in Tensorboard and perf_tool\n",
    "Now that the training is completed, you can see the trace files (...pt.trace.json) have been generated and now can be viewed.  Two types of information are produced by TensorBoard:\n",
    "\n",
    "Model Performance Tracking - While your workload is being processed in batches, you can track the progress of the training process on the dashboard in real-time by monitoring the modelâ€™s cost (loss) and accuracy.\n",
    "\n",
    "Profiling Analysis - Right after the last requested step was completed, the collected profiling data is analyzed by TensorBoard and then immediately submitted to your browser, without any need to wait till the training process is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8d01f1-1c80-4ba7-8384-2626e93f6ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=~/optimum-habana/examples/image-classification/hpu_profile --port 6006    # Your port selection may vary, default is 6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d6df7a-d03d-4994-b8c5-ac9099b68567",
   "metadata": {},
   "source": [
    "If you do not want to run the TensorBoard UI, you can take the same .json log files and use the habana_perf_tool that will parse the existing .json file and provide the same recommendations for performance enhancements, but in a text form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f599b9c-98c6-437e-ad9c-b12c7b09ea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!habana_perf_tool --trace /root/optimum-habana/examples/image-classification/hpu_profile/sc09wynn05-hls2_14734.1729284340533778439.pt.trace.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5821e9-fe68-4c76-93ef-b3b6c8492a02",
   "metadata": {},
   "source": [
    "### Using the Perfetto Trace Viewer\n",
    "Finally, to view the details of the Intel Gaudi Device itself, you can view the traces in the perfetto trace viewer.  \n",
    "\n",
    "This step requires you to set the `hl-prof-config` settings and the Environment variable `HABANA_PROFILE=1` as shown below, this will generate the .hltv file that can be viewed using https://perfetto.habana.ai.  Since this is using the Gaudi profiler, the runtime profiling commands need to be removed.  At the end of this run, you will see a `my_profiling_session_12345.hltv` file that can be loaded into the Perfetto browser.\n",
    "\n",
    "For More Information to enable your model to use the Habana Perfetto Trace viewer, you can refer to the documentation https://docs.habana.ai/en/latest/Profiling/Intel_Gaudi_Profiling/Getting_Started_with_Profiler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5291e8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "!hl-prof-config -e off -phase=multi-enq -g 1-20 -s my_profiling_session\n",
    "!export HABANA_PROFILE=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd26eb57-a519-4935-b7a5-92a56cdc1093",
   "metadata": {},
   "outputs": [],
   "source": [
    "!HABANA_PROFILE=1 python run_image_classification.py \\\n",
    "    --model_name_or_path microsoft/swin-base-patch4-window7-224-in22k \\\n",
    "    --dataset_name cifar10 \\\n",
    "    --output_dir /tmp/outputs/ \\\n",
    "    --remove_unused_columns False \\\n",
    "    --image_column_name img \\\n",
    "    --do_train \\\n",
    "    --learning_rate 3e-5 \\\n",
    "    --num_train_epochs 2 \\\n",
    "    --per_device_train_batch_size 64 \\\n",
    "    --evaluation_strategy no \\\n",
    "    --save_strategy no \\\n",
    "    --load_best_model_at_end False \\\n",
    "    --save_total_limit 3 \\\n",
    "    --seed 1337 \\\n",
    "    --use_habana \\\n",
    "    --use_lazy_mode \\\n",
    "    --report_to none \\\n",
    "    --use_hpu_graphs_for_training \\\n",
    "    --gaudi_config_name Habana/swin \\\n",
    "    --throughput_warmup_steps 3 \\\n",
    "    --bf16 \\\n",
    "    --overwrite_output_dir \\\n",
    "    --ignore_mismatched_sizes \n",
    "    #--profiling_warmup_steps 10 \\\n",
    "    #--profiling_steps 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1931bdba-bfdf-436e-981c-754ba2f50c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l *.hltv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb9a9ad-dc28-44f6-9af0-995932c3cfb0",
   "metadata": {},
   "source": [
    "Consult the [Analysis guide](https://docs.habana.ai/en/latest/Profiling/Intel_Gaudi_Profiling/Analysis.html) for performing a thorough analysis of the above .hltv profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc8d168",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
