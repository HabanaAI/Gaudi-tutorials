vllm_fork_url=https://github.com/HabanaAI/vllm-fork
llm_perf_url=https://github.com/ray-project/llmperf.git
client_type=vllmbench
client_script=performance.py
client_script_aux=vllmbench_processor.py
run_type=us-2048-bf16-1c-g3-1.20.0-cntx2k_cfg3_ril
run_description='Qual Factory run for RIL with context-2k and config group-3'
server_up_sleep=1200
debug=2
curl_query='What is Deeplearning?'
vllm_fork_dir=/root/vllm-fork
model_base=llama-3.1-8b-instruct
run_dir=runs/2025-03-17/meta-llama_Llama-3.1-8B-Instruct_vllm_vllmbench_us-2048-bf16-1c-g3-1.20.0-cntx2k_cfg3_ril
date_label=2025-03-17
run_label=meta-llama_Llama-3.1-8B-Instruct_vllm_vllmbench_us-2048-bf16-1c-g3-1.20.0-cntx2k_cfg3_ril
