{"GlobalRank": null, "LocalRank": 0, "Mode": "DynamicRange", "Nodes": {"model.layers.0.self_attn.qkv_proj": {"inputs": [[[4.625]]], "params": {"weight": [[0.67578125]]}}, "model.layers.0.self_attn.o_proj": {"inputs": [[[0.79296875]]], "outputs": [[[0.5546875]], [[0.000499725341796875]]], "params": {"weight": [[0.314453125]]}}, "model.layers.0.self_attn.attn.impl.matmul_qk": {"inputs": [[[2.828125]], [[13.8125]]]}, "model.layers.0.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[1.3359375]]]}, "model.layers.0.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[184.0]]]}, "model.layers.0.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[55.0]]]}, "model.layers.0.self_attn.attn.impl.k_cache": {"inputs": [[[13.8125]]]}, "model.layers.0.self_attn.attn.impl.v_cache": {"inputs": [[[1.3359375]]]}, "model.layers.0.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[22.625]], [[13.8125]], [[1.3359375]]], "outputs": [[[0.77734375]], [[1.0]]]}, "model.layers.0.mlp.gate_up_proj": {"inputs": [[[2.765625]]], "params": {"weight": [[0.59375]]}}, "model.layers.0.mlp.down_proj": {"inputs": [[[32.75]]], "outputs": [[[20.875]], [[5.841255187988281e-05]]], "params": {"weight": [[0.62109375]]}}, "model.layers.1.self_attn.qkv_proj": {"inputs": [[[5.84375]]], "params": {"weight": [[0.40234375]]}}, "model.layers.1.self_attn.o_proj": {"inputs": [[[1.8984375]]], "outputs": [[[0.65625]], [[5.841255187988281e-05]]], "params": {"weight": [[0.51953125]]}}, "model.layers.1.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.7109375]], [[14.125]]]}, "model.layers.1.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[2.515625]]]}, "model.layers.1.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[50.0]]]}, "model.layers.1.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[24.875]]]}, "model.layers.1.self_attn.attn.impl.k_cache": {"inputs": [[[14.125]]]}, "model.layers.1.self_attn.attn.impl.v_cache": {"inputs": [[[2.515625]]]}, "model.layers.1.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[13.5625]], [[14.0625]], [[2.375]]], "outputs": [[[1.8984375]], [[1.0]]]}, "model.layers.1.mlp.gate_up_proj": {"inputs": [[[18.5]]], "params": {"weight": [[1.1328125]]}}, "model.layers.1.mlp.down_proj": {"inputs": [[[1160.0]]], "outputs": [[[408.0]], [[1.6987323760986328e-06]]], "params": {"weight": [[0.6796875]]}}, "model.layers.2.self_attn.qkv_proj": {"inputs": [[[8.0]]], "params": {"weight": [[0.54296875]]}}, "model.layers.2.self_attn.o_proj": {"inputs": [[[1.59375]]], "outputs": [[[0.8515625]], [[288768.0]]], "params": {"weight": [[0.359375]]}}, "model.layers.2.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.609375]], [[15.5]]]}, "model.layers.2.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[2.796875]]]}, "model.layers.2.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[61.75]]]}, "model.layers.2.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[21.0]]]}, "model.layers.2.self_attn.attn.impl.k_cache": {"inputs": [[[15.5]]]}, "model.layers.2.self_attn.attn.impl.v_cache": {"inputs": [[[2.796875]]]}, "model.layers.2.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[12.5625]], [[15.5]], [[2.640625]]], "outputs": [[[1.3046875]], [[1.0]]]}, "model.layers.2.mlp.gate_up_proj": {"inputs": [[[6.625]]], "params": {"weight": [[0.4609375]]}}, "model.layers.2.mlp.down_proj": {"inputs": [[[3.53125]]], "outputs": [[[1.3203125]], [[288768.0]]], "params": {"weight": [[0.53125]]}}, "model.layers.3.self_attn.qkv_proj": {"inputs": [[[7.0625]]], "params": {"weight": [[0.3046875]]}}, "model.layers.3.self_attn.o_proj": {"inputs": [[[1.8203125]]], "outputs": [[[1.1171875]], [[0.0002899169921875]]], "params": {"weight": [[0.2431640625]]}}, "model.layers.3.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.796875]], [[20.875]]]}, "model.layers.3.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[2.875]]]}, "model.layers.3.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[40.25]]]}, "model.layers.3.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[24.875]]]}, "model.layers.3.self_attn.attn.impl.k_cache": {"inputs": [[[20.875]]]}, "model.layers.3.self_attn.attn.impl.v_cache": {"inputs": [[[2.875]]]}, "model.layers.3.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[13.0]], [[20.625]], [[2.59375]]], "outputs": [[[1.8203125]], [[1.0]]]}, "model.layers.3.mlp.gate_up_proj": {"inputs": [[[6.875]]], "params": {"weight": [[0.337890625]]}}, "model.layers.3.mlp.down_proj": {"inputs": [[[4.15625]]], "outputs": [[[1.0859375]], [[2.034864306880448e-22]]], "params": {"weight": [[0.490234375]]}}, "model.layers.4.self_attn.qkv_proj": {"inputs": [[[6.90625]]], "params": {"weight": [[0.416015625]]}}, "model.layers.4.self_attn.o_proj": {"inputs": [[[1.5]]], "outputs": [[[1.0078125]], [[1.6540288925170898e-06]]], "params": {"weight": [[0.3984375]]}}, "model.layers.4.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.7734375]], [[18.875]]]}, "model.layers.4.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[2.15625]]]}, "model.layers.4.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[56.75]]]}, "model.layers.4.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[31.875]]]}, "model.layers.4.self_attn.attn.impl.k_cache": {"inputs": [[[18.875]]]}, "model.layers.4.self_attn.attn.impl.v_cache": {"inputs": [[[2.15625]]]}, "model.layers.4.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[13.4375]], [[18.5]], [[2.15625]]], "outputs": [[[1.4765625]], [[1.0]]]}, "model.layers.4.mlp.gate_up_proj": {"inputs": [[[6.9375]]], "params": {"weight": [[0.515625]]}}, "model.layers.4.mlp.down_proj": {"inputs": [[[4.03125]]], "outputs": [[[1.3671875]], [[109568.0]]], "params": {"weight": [[0.470703125]]}}, "model.layers.5.self_attn.qkv_proj": {"inputs": [[[12.3125]]], "params": {"weight": [[1.109375]]}}, "model.layers.5.self_attn.o_proj": {"inputs": [[[2.046875]]], "outputs": [[[1.3671875]], [[1.6543612251060553e-21]]], "params": {"weight": [[0.447265625]]}}, "model.layers.5.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.703125]], [[20.125]]]}, "model.layers.5.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[2.9375]]]}, "model.layers.5.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[72.0]]]}, "model.layers.5.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[28.0]]]}, "model.layers.5.self_attn.attn.impl.k_cache": {"inputs": [[[20.125]]]}, "model.layers.5.self_attn.attn.impl.v_cache": {"inputs": [[[2.9375]]]}, "model.layers.5.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[13.3125]], [[20.125]], [[2.8125]]], "outputs": [[[1.90625]], [[1.0]]]}, "model.layers.5.mlp.gate_up_proj": {"inputs": [[[7.03125]]], "params": {"weight": [[0.357421875]]}}, "model.layers.5.mlp.down_proj": {"inputs": [[[4.75]]], "outputs": [[[1.6953125]], [[1146880.0]]], "params": {"weight": [[0.45703125]]}}, "model.layers.6.self_attn.qkv_proj": {"inputs": [[[8.6875]]], "params": {"weight": [[0.3828125]]}}, "model.layers.6.self_attn.o_proj": {"inputs": [[[1.8515625]]], "outputs": [[[1.2109375]], [[0.000446319580078125]]], "params": {"weight": [[0.259765625]]}}, "model.layers.6.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.8203125]], [[22.125]]]}, "model.layers.6.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[2.4375]]]}, "model.layers.6.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[67.5]]]}, "model.layers.6.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[26.375]]]}, "model.layers.6.self_attn.attn.impl.k_cache": {"inputs": [[[22.125]]]}, "model.layers.6.self_attn.attn.impl.v_cache": {"inputs": [[[2.4375]]]}, "model.layers.6.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[13.75]], [[21.125]], [[2.4375]]], "outputs": [[[1.8125]], [[1.0]]]}, "model.layers.6.mlp.gate_up_proj": {"inputs": [[[6.75]]], "params": {"weight": [[0.451171875]]}}, "model.layers.6.mlp.down_proj": {"inputs": [[[4.5]]], "outputs": [[[1.765625]], [[109568.0]]], "params": {"weight": [[0.625]]}}, "model.layers.7.self_attn.qkv_proj": {"inputs": [[[9.1875]]], "params": {"weight": [[0.33203125]]}}, "model.layers.7.self_attn.o_proj": {"inputs": [[[2.015625]]], "outputs": [[[1.5625]], [[0.0002899169921875]]], "params": {"weight": [[0.3671875]]}}, "model.layers.7.self_attn.attn.impl.matmul_qk": {"inputs": [[[2.046875]], [[20.375]]]}, "model.layers.7.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[3.4375]]]}, "model.layers.7.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[77.0]]]}, "model.layers.7.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[31.25]]]}, "model.layers.7.self_attn.attn.impl.k_cache": {"inputs": [[[20.375]]]}, "model.layers.7.self_attn.attn.impl.v_cache": {"inputs": [[[3.4375]]]}, "model.layers.7.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[15.5625]], [[18.5]], [[3.4375]]], "outputs": [[[1.734375]], [[1.0]]]}, "model.layers.7.mlp.gate_up_proj": {"inputs": [[[6.90625]]], "params": {"weight": [[0.5859375]]}}, "model.layers.7.mlp.down_proj": {"inputs": [[[3.90625]]], "outputs": [[[2.578125]], [[1146880.0]]], "params": {"weight": [[0.48046875]]}}, "model.layers.8.self_attn.qkv_proj": {"inputs": [[[12.1875]]], "params": {"weight": [[0.498046875]]}}, "model.layers.8.self_attn.o_proj": {"inputs": [[[2.09375]]], "outputs": [[[2.234375]], [[1.6540288925170898e-06]]], "params": {"weight": [[0.404296875]]}}, "model.layers.8.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.5859375]], [[20.5]]]}, "model.layers.8.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[2.703125]]]}, "model.layers.8.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[82.0]]]}, "model.layers.8.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[31.0]]]}, "model.layers.8.self_attn.attn.impl.k_cache": {"inputs": [[[20.5]]]}, "model.layers.8.self_attn.attn.impl.v_cache": {"inputs": [[[2.703125]]]}, "model.layers.8.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[12.75]], [[19.0]], [[2.421875]]], "outputs": [[[1.8828125]], [[1.0]]]}, "model.layers.8.mlp.gate_up_proj": {"inputs": [[[7.3125]]], "params": {"weight": [[0.546875]]}}, "model.layers.8.mlp.down_proj": {"inputs": [[[5.3125]]], "outputs": [[[2.46875]], [[49545216.0]]], "params": {"weight": [[0.578125]]}}, "model.layers.9.self_attn.qkv_proj": {"inputs": [[[9.875]]], "params": {"weight": [[0.412109375]]}}, "model.layers.9.self_attn.o_proj": {"inputs": [[[1.9921875]]], "outputs": [[[2.625]], [[181248.0]]], "params": {"weight": [[0.498046875]]}}, "model.layers.9.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.96875]], [[20.25]]]}, "model.layers.9.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[2.796875]]]}, "model.layers.9.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[101.0]]]}, "model.layers.9.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[41.25]]]}, "model.layers.9.self_attn.attn.impl.k_cache": {"inputs": [[[20.25]]]}, "model.layers.9.self_attn.attn.impl.v_cache": {"inputs": [[[2.796875]]]}, "model.layers.9.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[15.625]], [[19.375]], [[2.796875]]], "outputs": [[[1.828125]], [[1.0]]]}, "model.layers.9.mlp.gate_up_proj": {"inputs": [[[7.5]]], "params": {"weight": [[0.51171875]]}}, "model.layers.9.mlp.down_proj": {"inputs": [[[6.1875]]], "outputs": [[[2.453125]], [[25821184.0]]], "params": {"weight": [[0.5546875]]}}, "model.layers.10.self_attn.qkv_proj": {"inputs": [[[15.1875]]], "params": {"weight": [[0.38671875]]}}, "model.layers.10.self_attn.o_proj": {"inputs": [[[2.484375]]], "outputs": [[[1.796875]], [[1146880.0]]], "params": {"weight": [[0.60546875]]}}, "model.layers.10.self_attn.attn.impl.matmul_qk": {"inputs": [[[2.25]], [[17.375]]]}, "model.layers.10.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[3.046875]]]}, "model.layers.10.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[99.5]]]}, "model.layers.10.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[40.0]]]}, "model.layers.10.self_attn.attn.impl.k_cache": {"inputs": [[[17.375]]]}, "model.layers.10.self_attn.attn.impl.v_cache": {"inputs": [[[3.046875]]]}, "model.layers.10.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[16.5]], [[17.125]], [[3.046875]]], "outputs": [[[2.046875]], [[1.0]]]}, "model.layers.10.mlp.gate_up_proj": {"inputs": [[[7.875]]], "params": {"weight": [[0.57421875]]}}, "model.layers.10.mlp.down_proj": {"inputs": [[[11.3125]]], "outputs": [[[1.765625]], [[1146880.0]]], "params": {"weight": [[0.515625]]}}, "model.layers.11.self_attn.qkv_proj": {"inputs": [[[13.5]]], "params": {"weight": [[0.431640625]]}}, "model.layers.11.self_attn.o_proj": {"inputs": [[[2.109375]]], "outputs": [[[1.953125]], [[2.652406692504883e-06]]], "params": {"weight": [[0.6328125]]}}, "model.layers.11.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.71875]], [[24.625]]]}, "model.layers.11.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[3.171875]]]}, "model.layers.11.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[48.0]]]}, "model.layers.11.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[23.125]]]}, "model.layers.11.self_attn.attn.impl.k_cache": {"inputs": [[[24.625]]]}, "model.layers.11.self_attn.attn.impl.v_cache": {"inputs": [[[3.171875]]]}, "model.layers.11.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[12.25]], [[22.0]], [[2.75]]], "outputs": [[[1.890625]], [[1.0]]]}, "model.layers.11.mlp.gate_up_proj": {"inputs": [[[7.8125]]], "params": {"weight": [[0.63671875]]}}, "model.layers.11.mlp.down_proj": {"inputs": [[[10.125]]], "outputs": [[[2.921875]], [[0.000553131103515625]]], "params": {"weight": [[0.38671875]]}}, "model.layers.12.self_attn.qkv_proj": {"inputs": [[[12.75]]], "params": {"weight": [[0.73828125]]}}, "model.layers.12.self_attn.o_proj": {"inputs": [[[2.1875]]], "outputs": [[[3.34375]], [[270336.0]]], "params": {"weight": [[0.6953125]]}}, "model.layers.12.self_attn.attn.impl.matmul_qk": {"inputs": [[[2.390625]], [[18.625]]]}, "model.layers.12.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[3.875]]]}, "model.layers.12.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[36.0]]]}, "model.layers.12.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[19.5]]]}, "model.layers.12.self_attn.attn.impl.k_cache": {"inputs": [[[18.625]]]}, "model.layers.12.self_attn.attn.impl.v_cache": {"inputs": [[[3.875]]]}, "model.layers.12.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[15.375]], [[16.75]], [[3.140625]]], "outputs": [[[1.8125]], [[1.0]]]}, "model.layers.12.mlp.gate_up_proj": {"inputs": [[[7.71875]]], "params": {"weight": [[0.59765625]]}}, "model.layers.12.mlp.down_proj": {"inputs": [[[13.25]]], "outputs": [[[2.96875]], [[2.6138907356675675e-22]]], "params": {"weight": [[0.62890625]]}}, "model.layers.13.self_attn.qkv_proj": {"inputs": [[[14.0625]]], "params": {"weight": [[0.51953125]]}}, "model.layers.13.self_attn.o_proj": {"inputs": [[[2.65625]]], "outputs": [[[3.203125]], [[0.000499725341796875]]], "params": {"weight": [[0.462890625]]}}, "model.layers.13.self_attn.attn.impl.matmul_qk": {"inputs": [[[2.109375]], [[20.375]]]}, "model.layers.13.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[3.75]]]}, "model.layers.13.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[46.5]]]}, "model.layers.13.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[20.625]]]}, "model.layers.13.self_attn.attn.impl.k_cache": {"inputs": [[[20.375]]]}, "model.layers.13.self_attn.attn.impl.v_cache": {"inputs": [[[3.75]]]}, "model.layers.13.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[15.375]], [[19.625]], [[3.75]]], "outputs": [[[2.65625]], [[1.0]]]}, "model.layers.13.mlp.gate_up_proj": {"inputs": [[[7.15625]]], "params": {"weight": [[0.6640625]]}}, "model.layers.13.mlp.down_proj": {"inputs": [[[22.75]]], "outputs": [[[3.765625]], [[181248.0]]], "params": {"weight": [[0.451171875]]}}, "model.layers.14.self_attn.qkv_proj": {"inputs": [[[12.9375]]], "params": {"weight": [[0.56640625]]}}, "model.layers.14.self_attn.o_proj": {"inputs": [[[3.515625]]], "outputs": [[[5.71875]], [[288768.0]]], "params": {"weight": [[0.359375]]}}, "model.layers.14.self_attn.attn.impl.matmul_qk": {"inputs": [[[2.34375]], [[16.875]]]}, "model.layers.14.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[6.46875]]]}, "model.layers.14.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[60.25]]]}, "model.layers.14.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[26.0]]]}, "model.layers.14.self_attn.attn.impl.k_cache": {"inputs": [[[16.875]]]}, "model.layers.14.self_attn.attn.impl.v_cache": {"inputs": [[[6.46875]]]}, "model.layers.14.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[17.25]], [[15.75]], [[6.46875]]], "outputs": [[[2.5625]], [[1.0]]]}, "model.layers.14.mlp.gate_up_proj": {"inputs": [[[9.9375]]], "params": {"weight": [[0.7578125]]}}, "model.layers.14.mlp.down_proj": {"inputs": [[[17.0]]], "outputs": [[[6.125]], [[25821184.0]]], "params": {"weight": [[0.4453125]]}}, "model.layers.15.self_attn.qkv_proj": {"inputs": [[[8.625]]], "params": {"weight": [[0.486328125]]}}, "model.layers.15.self_attn.o_proj": {"inputs": [[[4.375]]], "outputs": [[[6.4375]], [[5.0923306460295766e-24]]], "params": {"weight": [[0.71875]]}}, "model.layers.15.self_attn.attn.impl.matmul_qk": {"inputs": [[[2.421875]], [[23.0]]]}, "model.layers.15.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[5.21875]]]}, "model.layers.15.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[54.5]]]}, "model.layers.15.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[18.0]]]}, "model.layers.15.self_attn.attn.impl.k_cache": {"inputs": [[[23.0]]]}, "model.layers.15.self_attn.attn.impl.v_cache": {"inputs": [[[5.21875]]]}, "model.layers.15.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[17.75]], [[21.875]], [[5.125]]], "outputs": [[[4.25]], [[1.0]]]}, "model.layers.15.mlp.gate_up_proj": {"inputs": [[[10.0]]], "params": {"weight": [[1.1953125]]}}, "model.layers.15.mlp.down_proj": {"inputs": [[[258.0]]], "outputs": [[[256.0]], [[0.000499725341796875]]], "params": {"weight": [[0.828125]]}}, "lm_head": {"inputs": [[[36.25]]], "params": {"weight": [[0.361328125]]}}}}