{"GlobalRank": null, "LocalRank": 0, "Mode": "DynamicRange", "Nodes": {"model.layers.0.self_attn.qkv_proj": {"inputs": [[[4.59375]]], "params": {"weight": [[0.67578125]]}}, "model.layers.0.self_attn.o_proj": {"inputs": [[[0.79296875]]], "outputs": [[[0.5546875]], [[6.280747422216628e+23]]], "params": {"weight": [[0.314453125]]}}, "model.layers.0.self_attn.attn.impl.matmul_qk": {"inputs": [[[2.828125]], [[13.8125]]]}, "model.layers.0.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[1.3359375]]]}, "model.layers.0.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[164.0]]]}, "model.layers.0.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[50.25]]]}, "model.layers.0.self_attn.attn.impl.k_cache": {"inputs": [[[13.8125]]]}, "model.layers.0.self_attn.attn.impl.v_cache": {"inputs": [[[1.3359375]]]}, "model.layers.0.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[22.625]], [[13.8125]], [[1.3359375]]], "outputs": [[[0.77734375]], [[1.0]]]}, "model.layers.0.mlp.gate_up_proj": {"inputs": [[[2.765625]]], "params": {"weight": [[0.59375]]}}, "model.layers.0.mlp.down_proj": {"inputs": [[[32.75]]], "outputs": [[[20.875]], [[5.501556952543137e+23]]], "params": {"weight": [[0.62109375]]}}, "model.layers.1.self_attn.qkv_proj": {"inputs": [[[6.09375]]], "params": {"weight": [[0.40234375]]}}, "model.layers.1.self_attn.o_proj": {"inputs": [[[1.8984375]]], "outputs": [[[0.6484375]], [[3.234821040765707e+23]]], "params": {"weight": [[0.51953125]]}}, "model.layers.1.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.6953125]], [[14.3125]]]}, "model.layers.1.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[2.375]]]}, "model.layers.1.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[40.5]]]}, "model.layers.1.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[24.5]]]}, "model.layers.1.self_attn.attn.impl.k_cache": {"inputs": [[[14.3125]]]}, "model.layers.1.self_attn.attn.impl.v_cache": {"inputs": [[[2.375]]]}, "model.layers.1.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[13.5625]], [[14.0625]], [[2.375]]], "outputs": [[[1.8984375]], [[1.0]]]}, "model.layers.1.mlp.gate_up_proj": {"inputs": [[[18.5]]], "params": {"weight": [[1.1328125]]}}, "model.layers.1.mlp.down_proj": {"inputs": [[[1160.0]]], "outputs": [[[408.0]], [[1.0178135157857321e+18]]], "params": {"weight": [[0.6796875]]}}, "model.layers.2.self_attn.qkv_proj": {"inputs": [[[8.0]]], "params": {"weight": [[0.54296875]]}}, "model.layers.2.self_attn.o_proj": {"inputs": [[[1.5078125]]], "outputs": [[[0.8515625]], [[3.8251168511244126e+23]]], "params": {"weight": [[0.359375]]}}, "model.layers.2.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.6015625]], [[15.5]]]}, "model.layers.2.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[2.828125]]]}, "model.layers.2.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[75.5]]]}, "model.layers.2.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[23.625]]]}, "model.layers.2.self_attn.attn.impl.k_cache": {"inputs": [[[15.5]]]}, "model.layers.2.self_attn.attn.impl.v_cache": {"inputs": [[[2.828125]]]}, "model.layers.2.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[12.5625]], [[15.5]], [[2.640625]]], "outputs": [[[1.296875]], [[1.0]]]}, "model.layers.2.mlp.gate_up_proj": {"inputs": [[[6.625]]], "params": {"weight": [[0.4609375]]}}, "model.layers.2.mlp.down_proj": {"inputs": [[[3.1875]]], "outputs": [[[1.3359375]], [[3.234821040765707e+23]]], "params": {"weight": [[0.53125]]}}, "model.layers.3.self_attn.qkv_proj": {"inputs": [[[7.65625]]], "params": {"weight": [[0.3046875]]}}, "model.layers.3.self_attn.o_proj": {"inputs": [[[1.859375]]], "outputs": [[[0.98828125]], [[3.234821040765707e+23]]], "params": {"weight": [[0.2431640625]]}}, "model.layers.3.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.8046875]], [[20.75]]]}, "model.layers.3.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[2.84375]]]}, "model.layers.3.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[63.0]]]}, "model.layers.3.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[36.25]]]}, "model.layers.3.self_attn.attn.impl.k_cache": {"inputs": [[[20.75]]]}, "model.layers.3.self_attn.attn.impl.v_cache": {"inputs": [[[2.84375]]]}, "model.layers.3.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[13.0]], [[20.625]], [[2.609375]]], "outputs": [[[1.859375]], [[1.0]]]}, "model.layers.3.mlp.gate_up_proj": {"inputs": [[[6.875]]], "params": {"weight": [[0.337890625]]}}, "model.layers.3.mlp.down_proj": {"inputs": [[[4.3125]]], "outputs": [[[1.2734375]], [[4776003633152.0]]], "params": {"weight": [[0.490234375]]}}, "model.layers.4.self_attn.qkv_proj": {"inputs": [[[8.75]]], "params": {"weight": [[0.416015625]]}}, "model.layers.4.self_attn.o_proj": {"inputs": [[[1.6015625]]], "outputs": [[[1.0234375]], [[1.6292164365900276e+23]]], "params": {"weight": [[0.3984375]]}}, "model.layers.4.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.6953125]], [[19.0]]]}, "model.layers.4.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[2.109375]]]}, "model.layers.4.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[137.0]]]}, "model.layers.4.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[25.875]]]}, "model.layers.4.self_attn.attn.impl.k_cache": {"inputs": [[[19.0]]]}, "model.layers.4.self_attn.attn.impl.v_cache": {"inputs": [[[2.109375]]]}, "model.layers.4.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[13.4375]], [[18.5]], [[2.015625]]], "outputs": [[[1.484375]], [[1.0]]]}, "model.layers.4.mlp.gate_up_proj": {"inputs": [[[6.9375]]], "params": {"weight": [[0.515625]]}}, "model.layers.4.mlp.down_proj": {"inputs": [[[4.28125]]], "outputs": [[[1.34375]], [[6.280747422216628e+23]]], "params": {"weight": [[0.470703125]]}}, "model.layers.5.self_attn.qkv_proj": {"inputs": [[[12.25]]], "params": {"weight": [[1.109375]]}}, "model.layers.5.self_attn.o_proj": {"inputs": [[[2.109375]]], "outputs": [[[1.359375]], [[1.6292164365900276e+23]]], "params": {"weight": [[0.447265625]]}}, "model.layers.5.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.65625]], [[21.25]]]}, "model.layers.5.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[2.9375]]]}, "model.layers.5.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[76.5]]]}, "model.layers.5.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[29.125]]]}, "model.layers.5.self_attn.attn.impl.k_cache": {"inputs": [[[21.25]]]}, "model.layers.5.self_attn.attn.impl.v_cache": {"inputs": [[[2.9375]]]}, "model.layers.5.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[13.375]], [[20.0]], [[2.828125]]], "outputs": [[[1.875]], [[1.0]]]}, "model.layers.5.mlp.gate_up_proj": {"inputs": [[[7.03125]]], "params": {"weight": [[0.357421875]]}}, "model.layers.5.mlp.down_proj": {"inputs": [[[4.75]]], "outputs": [[[1.6953125]], [[3.8251168511244126e+23]]], "params": {"weight": [[0.45703125]]}}, "model.layers.6.self_attn.qkv_proj": {"inputs": [[[8.75]]], "params": {"weight": [[0.3828125]]}}, "model.layers.6.self_attn.o_proj": {"inputs": [[[1.890625]]], "outputs": [[[1.203125]], [[4.810910854423451e+22]]], "params": {"weight": [[0.259765625]]}}, "model.layers.6.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.828125]], [[23.625]]]}, "model.layers.6.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[2.421875]]]}, "model.layers.6.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[52.75]]]}, "model.layers.6.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[28.0]]]}, "model.layers.6.self_attn.attn.impl.k_cache": {"inputs": [[[23.625]]]}, "model.layers.6.self_attn.attn.impl.v_cache": {"inputs": [[[2.421875]]]}, "model.layers.6.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[13.75]], [[21.125]], [[2.421875]]], "outputs": [[[1.8046875]], [[1.0]]]}, "model.layers.6.mlp.gate_up_proj": {"inputs": [[[6.75]]], "params": {"weight": [[0.451171875]]}}, "model.layers.6.mlp.down_proj": {"inputs": [[[4.34375]]], "outputs": [[[1.7734375]], [[7.656119366529843e+17]]], "params": {"weight": [[0.625]]}}, "model.layers.7.self_attn.qkv_proj": {"inputs": [[[9.3125]]], "params": {"weight": [[0.33203125]]}}, "model.layers.7.self_attn.o_proj": {"inputs": [[[1.9609375]]], "outputs": [[[1.5625]], [[1.6292164365900276e+23]]], "params": {"weight": [[0.3671875]]}}, "model.layers.7.self_attn.attn.impl.matmul_qk": {"inputs": [[[2.046875]], [[20.5]]]}, "model.layers.7.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[3.421875]]]}, "model.layers.7.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[75.0]]]}, "model.layers.7.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[34.0]]]}, "model.layers.7.self_attn.attn.impl.k_cache": {"inputs": [[[20.5]]]}, "model.layers.7.self_attn.attn.impl.v_cache": {"inputs": [[[3.421875]]]}, "model.layers.7.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[15.5]], [[18.5]], [[3.421875]]], "outputs": [[[1.71875]], [[1.0]]]}, "model.layers.7.mlp.gate_up_proj": {"inputs": [[[6.90625]]], "params": {"weight": [[0.5859375]]}}, "model.layers.7.mlp.down_proj": {"inputs": [[[3.640625]]], "outputs": [[[2.578125]], [[3.8251168511244126e+23]]], "params": {"weight": [[0.48046875]]}}, "model.layers.8.self_attn.qkv_proj": {"inputs": [[[12.25]]], "params": {"weight": [[0.498046875]]}}, "model.layers.8.self_attn.o_proj": {"inputs": [[[2.109375]]], "outputs": [[[2.1875]], [[8.92527265262363e+23]]], "params": {"weight": [[0.404296875]]}}, "model.layers.8.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.828125]], [[20.625]]]}, "model.layers.8.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[2.734375]]]}, "model.layers.8.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[67.5]]]}, "model.layers.8.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[34.75]]]}, "model.layers.8.self_attn.attn.impl.k_cache": {"inputs": [[[20.625]]]}, "model.layers.8.self_attn.attn.impl.v_cache": {"inputs": [[[2.734375]]]}, "model.layers.8.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[12.8125]], [[19.125]], [[2.4375]]], "outputs": [[[1.8671875]], [[1.0]]]}, "model.layers.8.mlp.gate_up_proj": {"inputs": [[[7.3125]]], "params": {"weight": [[0.546875]]}}, "model.layers.8.mlp.down_proj": {"inputs": [[[5.34375]]], "outputs": [[[2.5]], [[6.080046846694668e+22]]], "params": {"weight": [[0.578125]]}}, "model.layers.9.self_attn.qkv_proj": {"inputs": [[[9.875]]], "params": {"weight": [[0.412109375]]}}, "model.layers.9.self_attn.o_proj": {"inputs": [[[1.953125]]], "outputs": [[[2.328125]], [[6.080046846694668e+22]]], "params": {"weight": [[0.498046875]]}}, "model.layers.9.self_attn.attn.impl.matmul_qk": {"inputs": [[[2.25]], [[20.25]]]}, "model.layers.9.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[3.15625]]]}, "model.layers.9.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[74.0]]]}, "model.layers.9.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[28.375]]]}, "model.layers.9.self_attn.attn.impl.k_cache": {"inputs": [[[20.25]]]}, "model.layers.9.self_attn.attn.impl.v_cache": {"inputs": [[[3.15625]]]}, "model.layers.9.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[15.75]], [[19.25]], [[2.75]]], "outputs": [[[1.828125]], [[1.0]]]}, "model.layers.9.mlp.gate_up_proj": {"inputs": [[[7.5]]], "params": {"weight": [[0.51171875]]}}, "model.layers.9.mlp.down_proj": {"inputs": [[[7.15625]]], "outputs": [[[2.453125]], [[6.080046846694668e+22]]], "params": {"weight": [[0.5546875]]}}, "model.layers.10.self_attn.qkv_proj": {"inputs": [[[15.1875]]], "params": {"weight": [[0.38671875]]}}, "model.layers.10.self_attn.o_proj": {"inputs": [[[2.59375]]], "outputs": [[[1.828125]], [[3.234821040765707e+23]]], "params": {"weight": [[0.60546875]]}}, "model.layers.10.self_attn.attn.impl.matmul_qk": {"inputs": [[[2.203125]], [[17.625]]]}, "model.layers.10.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[3.046875]]]}, "model.layers.10.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[85.0]]]}, "model.layers.10.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[28.625]]]}, "model.layers.10.self_attn.attn.impl.k_cache": {"inputs": [[[17.625]]]}, "model.layers.10.self_attn.attn.impl.v_cache": {"inputs": [[[3.046875]]]}, "model.layers.10.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[16.5]], [[17.125]], [[3.046875]]], "outputs": [[[2.09375]], [[1.0]]]}, "model.layers.10.mlp.gate_up_proj": {"inputs": [[[7.875]]], "params": {"weight": [[0.57421875]]}}, "model.layers.10.mlp.down_proj": {"inputs": [[[11.375]]], "outputs": [[[1.8359375]], [[1.4226129029644806e+23]]], "params": {"weight": [[0.515625]]}}, "model.layers.11.self_attn.qkv_proj": {"inputs": [[[13.4375]]], "params": {"weight": [[0.431640625]]}}, "model.layers.11.self_attn.o_proj": {"inputs": [[[2.1875]]], "outputs": [[[2.03125]], [[5.643227947029226e+23]]], "params": {"weight": [[0.6328125]]}}, "model.layers.11.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.765625]], [[23.125]]]}, "model.layers.11.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[2.96875]]]}, "model.layers.11.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[39.5]]]}, "model.layers.11.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[23.25]]]}, "model.layers.11.self_attn.attn.impl.k_cache": {"inputs": [[[23.125]]]}, "model.layers.11.self_attn.attn.impl.v_cache": {"inputs": [[[2.96875]]]}, "model.layers.11.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[12.25]], [[22.0]], [[2.75]]], "outputs": [[[1.921875]], [[1.0]]]}, "model.layers.11.mlp.gate_up_proj": {"inputs": [[[7.8125]]], "params": {"weight": [[0.63671875]]}}, "model.layers.11.mlp.down_proj": {"inputs": [[[9.5625]]], "outputs": [[[2.90625]], [[5.973793600830101e+23]]], "params": {"weight": [[0.38671875]]}}, "model.layers.12.self_attn.qkv_proj": {"inputs": [[[12.6875]]], "params": {"weight": [[0.73828125]]}}, "model.layers.12.self_attn.o_proj": {"inputs": [[[2.21875]]], "outputs": [[[2.875]], [[5.0440315826549555e+17]]], "params": {"weight": [[0.6953125]]}}, "model.layers.12.self_attn.attn.impl.matmul_qk": {"inputs": [[[2.359375]], [[18.625]]]}, "model.layers.12.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[3.875]]]}, "model.layers.12.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[45.0]]]}, "model.layers.12.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[21.5]]]}, "model.layers.12.self_attn.attn.impl.k_cache": {"inputs": [[[18.625]]]}, "model.layers.12.self_attn.attn.impl.v_cache": {"inputs": [[[3.875]]]}, "model.layers.12.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[15.25]], [[16.75]], [[3.125]]], "outputs": [[[1.78125]], [[1.0]]]}, "model.layers.12.mlp.gate_up_proj": {"inputs": [[[7.71875]]], "params": {"weight": [[0.59765625]]}}, "model.layers.12.mlp.down_proj": {"inputs": [[[14.1875]]], "outputs": [[[3.1875]], [[5.71957152676053e+17]]], "params": {"weight": [[0.62890625]]}}, "model.layers.13.self_attn.qkv_proj": {"inputs": [[[14.9375]]], "params": {"weight": [[0.51953125]]}}, "model.layers.13.self_attn.o_proj": {"inputs": [[[2.671875]]], "outputs": [[[3.1875]], [[5.643227947029226e+23]]], "params": {"weight": [[0.462890625]]}}, "model.layers.13.self_attn.attn.impl.matmul_qk": {"inputs": [[[2.25]], [[20.375]]]}, "model.layers.13.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[3.78125]]]}, "model.layers.13.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[37.0]]]}, "model.layers.13.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[18.125]]]}, "model.layers.13.self_attn.attn.impl.k_cache": {"inputs": [[[20.375]]]}, "model.layers.13.self_attn.attn.impl.v_cache": {"inputs": [[[3.78125]]]}, "model.layers.13.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[15.375]], [[19.625]], [[3.78125]]], "outputs": [[[2.671875]], [[1.0]]]}, "model.layers.13.mlp.gate_up_proj": {"inputs": [[[7.15625]]], "params": {"weight": [[0.6640625]]}}, "model.layers.13.mlp.down_proj": {"inputs": [[[15.375]]], "outputs": [[[3.765625]], [[3.8251168511244126e+23]]], "params": {"weight": [[0.451171875]]}}, "model.layers.14.self_attn.qkv_proj": {"inputs": [[[13.8125]]], "params": {"weight": [[0.56640625]]}}, "model.layers.14.self_attn.o_proj": {"inputs": [[[3.078125]]], "outputs": [[[5.3125]], [[6.080046846694668e+22]]], "params": {"weight": [[0.359375]]}}, "model.layers.14.self_attn.attn.impl.matmul_qk": {"inputs": [[[2.609375]], [[16.875]]]}, "model.layers.14.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[6.4375]]]}, "model.layers.14.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[49.5]]]}, "model.layers.14.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[23.875]]]}, "model.layers.14.self_attn.attn.impl.k_cache": {"inputs": [[[16.875]]]}, "model.layers.14.self_attn.attn.impl.v_cache": {"inputs": [[[6.4375]]]}, "model.layers.14.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[17.25]], [[15.75]], [[6.4375]]], "outputs": [[[2.53125]], [[1.0]]]}, "model.layers.14.mlp.gate_up_proj": {"inputs": [[[9.9375]]], "params": {"weight": [[0.7578125]]}}, "model.layers.14.mlp.down_proj": {"inputs": [[[17.75]]], "outputs": [[[6.09375]], [[1.098878309078401e+18]]], "params": {"weight": [[0.4453125]]}}, "model.layers.15.self_attn.qkv_proj": {"inputs": [[[9.125]]], "params": {"weight": [[0.486328125]]}}, "model.layers.15.self_attn.o_proj": {"inputs": [[[4.375]]], "outputs": [[[6.6875]], [[5.973793600830101e+23]]], "params": {"weight": [[0.71875]]}}, "model.layers.15.self_attn.attn.impl.matmul_qk": {"inputs": [[[2.421875]], [[22.875]]]}, "model.layers.15.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[5.75]]]}, "model.layers.15.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[43.75]]]}, "model.layers.15.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[20.75]]]}, "model.layers.15.self_attn.attn.impl.k_cache": {"inputs": [[[22.875]]]}, "model.layers.15.self_attn.attn.impl.v_cache": {"inputs": [[[5.75]]]}, "model.layers.15.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[17.75]], [[21.875]], [[5.125]]], "outputs": [[[4.25]], [[1.0]]]}, "model.layers.15.mlp.gate_up_proj": {"inputs": [[[10.0]]], "params": {"weight": [[1.1953125]]}}, "model.layers.15.mlp.down_proj": {"inputs": [[[258.0]]], "outputs": [[[256.0]], [[5.494391545392005e+17]]], "params": {"weight": [[0.828125]]}}, "lm_head": {"inputs": [[[36.25]]], "params": {"weight": [[0.361328125]]}}}}