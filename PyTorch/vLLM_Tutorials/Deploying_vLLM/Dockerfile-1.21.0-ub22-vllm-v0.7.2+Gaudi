FROM vault.habana.ai/gaudi-docker/1.21.0/ubuntu24.04/habanalabs/pytorch-installer-2.6.0

# BUILD_ARGS="--build-arg http_proxy --build-arg https_proxy --build-arg no_proxy"
# CPREFIX="gar-registry.caas.intel.com/aice/"
# CNAME=vllm-v0.7.2-gaudi-ub22:1.21.0-555
# docker pull vault.habana.ai/gaudi-docker/1.21.0/ubuntu24.04/habanalabs/pytorch-installer-2.6.0
# docker build -f Dockerfile-1.21.0-ub22-vllm-v0.7.2+Gaudi -t ${CPREFIX}${CNAME} $BUILD_ARGS .

ENV OMPI_MCA_btl_vader_single_copy_mechanism=none

RUN apt update && \
	apt install -y gettext moreutils jq && \
	ln -sf /usr/bin/python3 /usr/bin/python
WORKDIR /root

## Install vllm-fork inside the container
RUN git clone https://github.com/HabanaAI/vllm-fork.git && \
    cd vllm-fork && \
    git checkout v0.7.2+Gaudi-1.21.0 && \
    pip install -v -e .

## Install additional packages
RUN pip install datasets &&\
    pip install pandas
    

## Copy the glue logic
RUN mkdir -p /root/scripts
COPY entrypoint.sh generate_vars.py settings_vllm.csv template_vllm_server.sh varlist* perftest* /root/scripts
RUN chmod +x /root/scripts/*.sh

EXPOSE 22

# Start our script 
WORKDIR /root/scripts
ENTRYPOINT ["/root/scripts/entrypoint.sh"]
